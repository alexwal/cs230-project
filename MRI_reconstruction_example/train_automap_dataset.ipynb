{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use TF 2.0 (on EC2 instance running Deep Learning AMI):\n",
    "# source activate tensorflow_p36\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install tensorflow-gpu==2.0.0-alpha0\n",
    "\n",
    "# But then later decided wanted even newer GPU stuff and \"in that conda env, ran:\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install --upgrade pip\n",
    "# pip install wrapt --ignore-installed # ran this because had an error\n",
    "# pip install  tf-nightly-gpu-2.0-preview\n",
    "\n",
    "# Result: Successfully installed tf-nightly-gpu-2.0-preview-2.0.0.dev20190531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging import version\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__) # make sure >= 2.0.0-dev20190527\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cs230_project_utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU usage logging (TF 2.0+)\n",
    "\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load cifar 100 (should already be shuffled)\n",
    "# (x_train, labels_train), (x_test, labels_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# # Convert x_train to float32, grayscale\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_train =(0.299 * x_train[..., 0] + 0.587 * x_train[..., 1] +  0.114 * x_train[..., 2]) / 255.0\n",
    "\n",
    "# # Convert x_test to float32, grayscale \n",
    "# x_test = x_test.astype('float32')\n",
    "# x_test =(0.299 * x_test[..., 0] + 0.587 * x_test[..., 1] +  0.114 * x_test[..., 2]) / 255.0\n",
    "\n",
    "# # Split x_test to create x_dev\n",
    "# x_dev, x_test = x_test[:len(x_test) // 2], x_test[len(x_test) // 2:]\n",
    "\n",
    "# # Show stats of images\n",
    "# print('Shape of x_train: ' + str(x_train.shape))\n",
    "# print('Shape of x_test: ' + str(x_test.shape))\n",
    "# print('Shape of x_dev: ' + str(x_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def centered_2d_fft(tensor):\n",
    "#     ''' \n",
    "#     Input\n",
    "#         tensor: 2D tensor of shape [height, width]\n",
    "#     Returns\n",
    "#         fft: centered_2d_fft(tensor) / sqrt(product(tensor.shape)) as dtype tf.complex64\n",
    "    \n",
    "#     Inverse: ifft = tf.signal.ifft2d(fft) (if image, use abs(ifft) to view)\n",
    "    \n",
    "#     Notes:\n",
    "    \n",
    "#     The inverse ffts aren't perfect but pretty close (suspect this is due to casting of dtypes).\n",
    "#     Difference b/w image and ifft is imperceptible (visually).\n",
    "    \n",
    "#     y = an image\n",
    "#     np.allclose(tf.math.real(centered_2d_fft(y0)).numpy(), x0[..., 0], atol=5e-3) -> True\n",
    "#     np.allclose(tf.math.imag(centered_2d_fft(y0)).numpy(), x0[..., 1], atol=5e-2) -> True\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     tensor = tf.cast(tensor, tf.complex64)\n",
    "#     fft_unshifted = tf.signal.fft2d(tensor)\n",
    "#     fft = tf.signal.fftshift(fft_unshifted)\n",
    "#     return fft\n",
    "\n",
    "# def cifar_parser(sample):\n",
    "#     # Returns: (fft, image reconstruction) pairs for automap model\n",
    "    \n",
    "#     # Image must be 3-dim\n",
    "#     sample = tf.expand_dims(sample, -1)\n",
    "#     resized = tf.image.resize(sample, [256, 256])\n",
    "#     fft = centered_2d_fft(tf.squeeze(resized))\n",
    "#     fft = tf.expand_dims(fft, -1) # tf.signal.fft2d expects 2D input, so we undo the squeeze() from before\n",
    "    \n",
    "#     # Separate real and imaginary components into separate channels (models operate on floats)\n",
    "#     real = tf.math.real(fft)\n",
    "#     imaginary = tf.math.imag(fft)\n",
    "#     fft = tf.concat([real, imaginary], axis=-1)\n",
    "    \n",
    "#     return fft, resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_locations, batch_size, buffer_size, include_all_parsed_features):\n",
    "    '''\n",
    "    Returns iterator of automap data located in `data_locations`.\n",
    "    \n",
    "    data_locations:  A string, a list of strings, or a `tf.Tensor` of string type\n",
    "    (scalar or vector), representing the filename glob (i.e. shell wildcard)\n",
    "    pattern(s) that will be matched.\n",
    "    '''\n",
    "    filenames = tf.data.TFRecordDataset.list_files(data_locations)\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "    # Use `tf.parse_single_example()` to extract data from a `tf.Example`\n",
    "    # protocol buffer, and perform any additional per-example processing.\n",
    "    def parser(record):\n",
    "        keys_to_features = {\n",
    "            \"path\": tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "            \"sequence_index\": tf.io.FixedLenFeature((), tf.int64, -1),\n",
    "            \"fft\": tf.io.FixedLenFeature((), tf.string, ''),\n",
    "            \"image\": tf.io.FixedLenFeature((), tf.string, ''),\n",
    "            \"dimension\": tf.io.FixedLenFeature((), tf.int64, -1),\n",
    "            \"class\": tf.io.FixedLenFeature((), tf.int64, -1)\n",
    "        }\n",
    "        parsed = tf.io.parse_single_example(record, keys_to_features)\n",
    "        \n",
    "        # Perform additional preprocessing on the parsed data.\n",
    "        parsed['fft'] = tf.io.decode_raw(parsed['fft'], out_type=tf.float32)\n",
    "        parsed['image'] = tf.io.decode_raw(parsed['image'], out_type=tf.float32)\n",
    "        \n",
    "        parsed['fft'] = tf.reshape(parsed['fft'], [parsed['dimension'], parsed['dimension'], 2])\n",
    "        parsed['image'] = tf.reshape(parsed['image'], [parsed['dimension'], parsed['dimension'], 1])\n",
    "        \n",
    "        if include_all_parsed_features:\n",
    "            return parsed\n",
    "        \n",
    "        # We only want input and expected output during training stage (X, Y)\n",
    "        return parsed['fft'], parsed['image']\n",
    "    \n",
    "    # Use `Dataset.map()` to build a pair of a feature dictionary and a label\n",
    "    # tensor for each example.\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Each element of `dataset` is tuple containing a dictionary of features\n",
    "    # (in which each value is a batch of values for that feature), and a batch of\n",
    "    # labels.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data.Datasets to preprocess and iterate data efficiently\n",
    "\n",
    "# include class_0?\n",
    "test_data_locations = ['/home/ubuntu/cs230/data/tfrecords/test/class_0/*.tfrecord'] # only bad for test\n",
    "dev_data_locations = ['/home/ubuntu/cs230/data/tfrecords/dev/class_0/*.tfrecord'] # only bad for dev\n",
    "train_data_locations = ['/home/ubuntu/cs230/data/tfrecords/*/class_1/*.tfrecord'] # only good for train (note: first * is weird but prev had separated out 0, 1 for dev and test too but should train on all 1 classes and test on rest)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "test_dataset = load_dataset(test_data_locations, batch_size=batch_size, buffer_size=1, include_all_parsed_features=False) # no need to shuffle test and dev\n",
    "dev_dataset = load_dataset(dev_data_locations, batch_size=batch_size, buffer_size=1, include_all_parsed_features=False)\n",
    "train_dataset = load_dataset(train_data_locations, batch_size=batch_size, buffer_size=512, include_all_parsed_features=False) # good to shuffle train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First batch of each dataset to be used in plotting images periodically to tensorboard\n",
    "\n",
    "first_test_batch = next(iter(test_dataset))\n",
    "first_dev_batch = next(iter(dev_dataset))\n",
    "first_train_batch = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A metric to use during training\n",
    "def mean_PSNR(y_true, y_pred):\n",
    "    max_value = 1.0\n",
    "    MSE = tf.reduce_mean(tf.square(y_true - y_pred), axis=[1, 2, 3])\n",
    "    PSNR = 10 * tf.math.log(tf.divide(max_value ** 2, MSE)) / tf.math.log(tf.constant(10, dtype=y_pred.dtype))\n",
    "    mean = tf.reduce_mean(PSNR)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uncompiled_automap_model():\n",
    "\n",
    "    N = 256\n",
    "    X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "    # Paper says 1% multiplicative gaussian noise (this multiplies by 1-centered gaussian\n",
    "    # having stddev = sqrt(rate / (1 - rate)) (here, 0.00032...)\n",
    "    noisy_X = tf.keras.layers.GaussianDropout(rate=1e-7)(X) # spatial dimension: 256\n",
    "    # Note: (we could corrupt when training with cifar, but maybe not other dataset?)\n",
    "\n",
    "    ds1 = tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "    ds1 = tf.keras.layers.MaxPool2D(pool_size=2)(ds1) # (new) downsample to spatial dimension: 128\n",
    "\n",
    "    ds2 = tf.keras.layers.Conv2D(2, (3, 3), strides=(1, 1), activation='relu', padding='same')(ds1)\n",
    "    ds2 = tf.keras.layers.MaxPool2D(pool_size=2)(ds2) # (new) downsample to spatial dimension: 64\n",
    "\n",
    "    ds_flat = tf.keras.layers.Flatten()(ds2)\n",
    "\n",
    "    # fc1 = tf.keras.layers.Dense(8192)(ds_flat)\n",
    "    fc1 = tf.keras.layers.Dense(8192, activation='tanh')(ds_flat)\n",
    "    fc2 = tf.keras.layers.Dense(4096, activation='tanh')(fc1)\n",
    "    fc3 = tf.keras.layers.Dense(4096, activation='tanh')(fc2)\n",
    "\n",
    "    fc_output = tf.keras.layers.Reshape([64, 64, 1])(fc3)\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(256, (5, 5), strides=(1, 1), activation='relu', padding='same')(fc_output)\n",
    "    conv1 = tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=2, activation='relu', padding='same')(conv1) # (new) upsample to spatial dimension 128\n",
    "\n",
    "    # L1 regularization to encourage sparsity\n",
    "    conv2 = tf.keras.layers.Conv2D(256, (5, 5), strides=(1, 1), activation='relu', padding='same',\n",
    "                                       kernel_regularizer=tf.keras.regularizers.l1(1e-4))(conv1)\n",
    "    conv2 = tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=2, activation='relu', padding='same',\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l1(1e-4))(conv2) # (new) upsample to spatial dimension 256\n",
    "\n",
    "    Y_pred = tf.keras.layers.Conv2DTranspose(1, (7, 7), strides=1, activation='relu', padding='same')(conv2) # upsample to spatial dimension 256\n",
    "\n",
    "    model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compiled_automap_model():\n",
    "    multi_gpu = False\n",
    "    # Distribute training across GPUs (each GPU receives identical updates to weights but different batches w/\n",
    "    # mirrored strategy). Restricts callbacks we can use\n",
    "    if multi_gpu:\n",
    "        mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "        with mirrored_strategy.scope():\n",
    "            model = load_uncompiled_automap_model()\n",
    "            model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(), metrics=[mean_PSNR])\n",
    "    else:\n",
    "        model = load_uncompiled_automap_model()\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(), metrics=[mean_PSNR])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom learning rate schedule\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases as epochs progress.\n",
    "    \"\"\"\n",
    "    learning_rate = 2e-4\n",
    "    if epoch > 100:\n",
    "        learning_rate = 1e-4\n",
    "    if epoch > 150:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 200:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 250:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 300:\n",
    "        learning_rate = 1e-6\n",
    "    elif epoch > 350:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 400:\n",
    "        learning_rate = 1e-6\n",
    "    elif epoch > 600:\n",
    "        learning_rate = 1e-7\n",
    "    elif epoch > 800:\n",
    "        learning_rate = 5e-6\n",
    "    elif epoch > 900:\n",
    "        learning_rate = 1e-7\n",
    "\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "        \n",
    "    return learning_rate\n",
    "\n",
    "# Show reconstructions during training\n",
    "\n",
    "def plot_fft_reconstructions(batch, logs):\n",
    "    plot_frequency = 100\n",
    "    \n",
    "    if batch % plot_frequency != 0:\n",
    "        return\n",
    "    \n",
    "    batches = [(first_test_batch, 'Test'), (first_dev_batch, 'Dev'), (first_train_batch, 'Train')]\n",
    "    \n",
    "    for dataset_batch, name in batches:\n",
    "        x, y = dataset_batch\n",
    "        y = y.numpy()\n",
    "        y_pred = model.predict(x)\n",
    "\n",
    "        with file_writer.as_default():\n",
    "            for i in range(min(len(y), 8)):\n",
    "                prediction, ground_truth = y_pred[i:i + 1, ...], y[i:i + 1, ...]\n",
    "                tf.summary.image(\"{} Image {} (Prediction)\".format(name, i), prediction, max_outputs=1, step=batch)\n",
    "                tf.summary.image(\"{} Image {} (Ground Truth)\".format(name, i), ground_truth, max_outputs=1, step=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_compiled_automap_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where logs will be saved\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks to use in various stages of training\n",
    "\n",
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintAndLogLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('learning rate (end of epoch)', data=model.optimizer.lr.numpy(), step=epoch)\n",
    "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "                                                          model.optimizer.lr.numpy()))\n",
    "\n",
    "plot_images_callback = tf.keras.callbacks.LambdaCallback(on_batch_end=plot_fft_reconstructions)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=2, update_freq=200,\n",
    "                                                      profile_batch=0) # workaround for: https://github.com/tensorflow/tensorboard/issues/2084\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25,\n",
    "                              patience=2, min_lr=1e-8)\n",
    "\n",
    "callbacks = [tensorboard_callback, lr_callback, plot_images_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=dev_dataset,\n",
    "    verbose=1, # set to 0 to suppress chatty output and use Tensorboard instead\n",
    "    epochs=1000,\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=True) # see if speeds things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Uncomment to save model\n",
    "# saved_model_path = 'automap_our_dataset_original_paper_model_with_up_down_sampling' (had out 256 channels... bad)\n",
    "\n",
    "saved_model_path = 'automap_our_dataset_original_paper_model_with_up_down_sampling_single_GPU_v5'\n",
    "\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"loss\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_loss\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"mean_PSNR\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_mean_PSNR\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"µ ( PSNR ) \")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict on a test batch\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    x, y = x.numpy(), y.numpy()\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    # Inspect output\n",
    "\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        fft_mag = x[i, ..., 0]\n",
    "        fft_ang = x[i, ..., 1]\n",
    "        c = None #int(cls[i])\n",
    "        reconstruction = y_pred[i, ..., 0]\n",
    "        reconstruction[reconstruction < 0] = 0\n",
    "        reconstruction[reconstruction > 1] = 1\n",
    "        image = y[i, ..., 0]\n",
    "\n",
    "        print('Class: {}'.format(c))\n",
    "\n",
    "        MSE = utils.signal_processing.mean_square_error(reconstruction, image)\n",
    "        PSNR = utils.signal_processing.PSNR(reconstruction, image, max_value=1.0)\n",
    "\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.title('Reconstruction (MSE: {:0.5f}, PSNR: {:0.5f})'.format(MSE, PSNR))\n",
    "        utils.plot.imshowgray(reconstruction)\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.title('FFT (Magnitude)')\n",
    "        utils.plot.imshowfft(fft_mag)\n",
    "\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.title('Expected reconstruction')\n",
    "        utils.plot.imshowgray(image)\n",
    "\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.title('FFT (Phase)')\n",
    "        utils.plot.imshowgray(fft_ang)\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In theory, in TF 2.0 we should be able to see Tensorboard in this notebook with magics:\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs\n",
    "\n",
    "# Clear logs if needed\n",
    "# !rm -rf logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/1l4z7u062nvlhrz/MRI_Kspace.dat\n",
    "# See https://github.com/kmjohnson3/ML4MI_BootCamp/blob/fe9d96cd9f68db073a44f9dc9a015533a008d0a7/ImageReconstruction/CoLab_AutoMap_Recon.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll -h MRI_Kspace.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore these old models (here for ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "#     N = 256\n",
    "#     small_N = N // 4 # after downsampling by 2 twice\n",
    "    \n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-6)(X)\n",
    "#     conv_downsample1 = tf.keras.layers.Conv2D(16, (4, 4), strides=(2, 2), activation='tanh', padding='same')(noisy_X)\n",
    "# #     conv_downsample2 = tf.keras.layers.Conv2D(4, (4, 4), strides=(1, 1), activation='tanh', padding='same')(conv_downsample1)\n",
    "#     conv_downsample3 = tf.keras.layers.Conv2D(2, (4, 4), strides=(2, 2), activation='tanh', padding='same')(conv_downsample1)\n",
    "#     X1 = tf.keras.layers.Flatten()(conv_downsample3)\n",
    "    \n",
    "#     # Workaround for: ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\n",
    "#     X1 = tf.keras.layers.Reshape(target_shape=((small_N ** 2) * 2,))(X1)\n",
    "    \n",
    "#     fc1 = tf.keras.layers.Dense((small_N ** 2) * 1, activation = 'tanh')(X1)\n",
    "#     fc1_DO = tf.keras.layers.Dropout(0.1)(fc1)\n",
    "    \n",
    "#     fc2 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc1_DO)\n",
    "#     fc2_DO = tf.keras.layers.Dropout(0.1)(fc2)\n",
    "\n",
    "#     fc3 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc2_DO)\n",
    "#     X2 = tf.keras.layers.Reshape((small_N, small_N, 1))(fc3)\n",
    "#     conv1_1 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(1e-4))(X2)\n",
    "#     conv1_2 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(1e-4))(conv1_1)\n",
    "#     conv1_3a = tf.keras.layers.Conv2DTranspose(small_N, 9, activation='relu', padding='same')(conv1_2)\n",
    "#     conv1_3b = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3a)\n",
    "#     conv1_3c = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3b)\n",
    "    \n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, 1, activation = 'linear', padding='same')(conv1_3c)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "    \n",
    "#     # this one's solid, but I believe we'll need a few hours to train it.\n",
    "    \n",
    "#     N = 256\n",
    "#     F = N\n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "#     # Half-assed data augmentation\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "#     # These layers all halve the spatial dimension (but also each output 256 channels)\n",
    "#     conv1 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "#     pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "#     conv2 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "#     pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "#     conv3 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "#     pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "#     conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "#     pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "#     conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4)\n",
    "#     pool5 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv5) # shape: (8, 8, F)\n",
    "\n",
    "#     conv6 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool5)\n",
    "#     pool6 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv6) # shape: (4, 4, F)\n",
    "\n",
    "#     # A \"FC-like\" layer for fun before we do upsampling\n",
    "#     conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(pool6) # spatial dim: 4\n",
    "\n",
    "#     # These transposed convolutions upsample spatial dimension by 2\n",
    "#     t_conv1 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(conv7) # spatial dim: 8\n",
    "#     t_conv2 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv1) # spatial dim: 16\n",
    "#     t_conv3 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv2) # spatial dim: 32\n",
    "#     t_conv4 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv3) # spatial dim: 64\n",
    "#     t_conv5 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv4) # spatial dim: 128\n",
    "    \n",
    "#     Y_pred = tf.keras.layers.Conv2DTranspose(1, 4, strides=2, activation='linear', padding='same')(t_conv5) # spatial dim: 256\n",
    "\n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "#     return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no transposed conv, just upsample (first try, guessing too much data lost in middle)\n",
    "\n",
    "# def load_uncompiled_automap_model():\n",
    "\n",
    "#     N = 256\n",
    "#     F = N\n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "#     # Half-assed data augmentation\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "#     # Downsampling\n",
    "\n",
    "#     conv1 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "#     pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "#     conv2 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "#     pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "#     conv3 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "#     pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "#     conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "#     pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "#     conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4)\n",
    "#     pool5 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv5) # shape: (8, 8, F)\n",
    "\n",
    "#     conv6 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool5)\n",
    "#     pool6 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv6) # shape: (4, 4, F)\n",
    "\n",
    "#     # Some pointwise convoluations before finally upsampling\n",
    "\n",
    "#     conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(pool6) # shape: (4, 4, F)\n",
    "#     conv8 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv7) # shape: (4, 4, F)\n",
    "#     conv9 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv8) # shape: (4, 4, F)\n",
    "\n",
    "#     # Upsampling\n",
    "\n",
    "#     conv10 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(conv9)\n",
    "#     pool10 = tf.keras.layers.UpSampling2D(2)(conv10) # shape: (8, 8, F)\n",
    "\n",
    "#     conv11 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool10)\n",
    "#     pool11 = tf.keras.layers.UpSampling2D(2)(conv11) # shape: (16, 16, F)\n",
    "\n",
    "#     conv12 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool11)\n",
    "#     pool12 = tf.keras.layers.UpSampling2D(2)(conv12) # shape: (32, 32, F)\n",
    "\n",
    "#     conv13 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool12)\n",
    "#     pool13 = tf.keras.layers.UpSampling2D(2)(conv13) # shape: (64, 64, F)\n",
    "\n",
    "#     conv14 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool13)\n",
    "#     pool14 = tf.keras.layers.UpSampling2D(2)(conv14) # shape: (128, 128, F)\n",
    "\n",
    "#     conv15 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool14)\n",
    "#     pool15 = tf.keras.layers.UpSampling2D(2)(conv15) # shape: (256, 256, F)\n",
    "\n",
    "#     # One more to smooth things out\n",
    "\n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, (3, 3), strides=(1, 1), activation='linear', padding='same')(pool15)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "\n",
    "#     N = 256\n",
    "#     F = N\n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "#     # Half-assed data augmentation\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "#     # Downsampling\n",
    "\n",
    "#     conv1 = tf.keras.layers.Conv2D(F, (9, 9), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "#     pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "#     conv2 = tf.keras.layers.Conv2D(F, (7, 7), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "#     pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "#     conv3 = tf.keras.layers.Conv2D(F, (5, 5), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "#     pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "#     conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "#     pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "#     # Some pointwise convolutions before finally upsampling\n",
    "\n",
    "#     conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4) # shape: (16, 16, F)\n",
    "#     conv6 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv5) # shape: (16, 16, F)\n",
    "#     conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv6) # shape: (16, 16, F)\n",
    "\n",
    "#     # Upsampling\n",
    "\n",
    "#     t_conv8 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(conv7)\n",
    "#     t_conv9 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv8)\n",
    "#     t_conv10 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv9)\n",
    "#     t_conv11 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv10)\n",
    "    \n",
    "# #     pool8 = tf.keras.layers.UpSampling2D(2)(conv7) # shape: (32, 32, F)\n",
    "# #     conv8 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool8)\n",
    "\n",
    "# #     pool9 = tf.keras.layers.UpSampling2D(2)(conv8) # shape: (64, 64, F)\n",
    "# #     conv9 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool9)\n",
    "\n",
    "# #     pool10 = tf.keras.layers.UpSampling2D(2)(conv9) # shape: (128, 128, F)\n",
    "# #     conv10 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool10)\n",
    "\n",
    "# #     pool11 = tf.keras.layers.UpSampling2D(2)(conv10) # shape: (256, 256, F)\n",
    "# #     conv11 = tf.keras.layers.Conv2D(F, (5, 5), strides=(1, 1), activation='relu', padding='same')(pool11)\n",
    "\n",
    "#     # One more to smooth things out\n",
    "\n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, (2, 2), strides=(1, 1), activation='linear', padding='same')(t_conv11)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
