{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use TF 2.0 (on EC2 instance running Deep Learning AMI):\n",
    "# source activate tensorflow_p36\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install tensorflow-gpu==2.0.0-alpha0\n",
    "\n",
    "# But then later decided wanted even newer GPU stuff and in that conda env, ran:\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install --upgrade pip\n",
    "# pip install wrapt --ignore-installed # ran this because had an error\n",
    "# pip install  tf-nightly-gpu-2.0-preview\n",
    "\n",
    "# Result: Successfully installed tf-nightly-gpu-2.0-preview-2.0.0.dev20190527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0-dev20190527\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__) # make sure >= 2.0.0-dev20190527\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cs230_project_utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU usage logging (TF 2.0+)\n",
    "\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (50000, 32, 32)\n",
      "Shape of x_test: (5000, 32, 32)\n",
      "Shape of x_dev: (5000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load cifar 100 (should already be shuffled)\n",
    "(x_train, labels_train), (x_test, labels_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# Convert x_train to float32, grayscale\n",
    "x_train = x_train.astype('float32')\n",
    "x_train =(0.299 * x_train[..., 0] + 0.587 * x_train[..., 1] +  0.114 * x_train[..., 2]) / 255.0\n",
    "\n",
    "# Convert x_test to float32, grayscale \n",
    "x_test = x_test.astype('float32')\n",
    "x_test =(0.299 * x_test[..., 0] + 0.587 * x_test[..., 1] +  0.114 * x_test[..., 2]) / 255.0\n",
    "\n",
    "# Split x_test to create x_dev\n",
    "x_dev, x_test = x_test[:len(x_test) // 2], x_test[len(x_test) // 2:]\n",
    "\n",
    "# Show stats of images\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of x_dev: ' + str(x_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_2d_scaled_and_centered(tensor):\n",
    "    ''' \n",
    "    Input\n",
    "        tensor: 2D tensor of shape [height, width]\n",
    "    Returns\n",
    "        fft: centered_2d_fft(tensor) / sqrt(product(tensor.shape)) as dtype tf.complex64\n",
    "        \n",
    "    Tested and np.allclose(fft, numpy_fft, atol=1e-5) returns True, where\n",
    "    numpy_fft = np.abs(utils.signal_processing.fft_2D_centered(tensor)).\n",
    "    \n",
    "    '''\n",
    "    complex_valued = tf.cast(tf.squeeze(tensor), tf.complex64)\n",
    "    fft = tf.signal.fft2d(complex_valued)\n",
    "    scale = tf.math.sqrt(tf.reduce_prod(tf.cast(fft.shape, tf.float32)))\n",
    "    fft_scaled = fft / tf.cast(scale, tf.complex64)\n",
    "    centered_fft = tf.signal.fftshift(fft_scaled)\n",
    "    return centered_fft\n",
    "\n",
    "def cifar_parser(sample):\n",
    "    # Returns: (fft, image reconstruction) pairs for automap model\n",
    "    \n",
    "    # Image must be 3-dim\n",
    "    sample = tf.expand_dims(sample, -1)\n",
    "    resized = tf.image.resize(sample, [256, 256])\n",
    "    fft = fft_2d_scaled_and_centered(tf.squeeze(resized))\n",
    "    fft = tf.expand_dims(fft, -1) # tf.signal.fft2d expects 2D input, so we undo the squeeze() from before\n",
    "    \n",
    "    # Separate magnitude and phase into separate dimensions\n",
    "    magnitude = tf.math.abs(fft)\n",
    "    phase = tf.math.angle(fft)\n",
    "    fft = tf.concat([magnitude, phase], axis=-1)\n",
    "    \n",
    "    return fft, resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data.Datasets to preprocess and iterate data efficiently\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.map(cifar_parser)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=4096)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.map(cifar_parser)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "dev_dataset = tf.data.Dataset.from_tensor_slices(x_dev)\n",
    "dev_dataset = dev_dataset.map(cifar_parser)\n",
    "dev_dataset = dev_dataset.shuffle(buffer_size=128)\n",
    "dev_dataset = dev_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A metric to use during training\n",
    "def mean_PSNR(y_true, y_pred):\n",
    "    max_value = 1.0\n",
    "    MSE = tf.reduce_mean(tf.square(y_true - y_pred), axis=[1, 2, 3])\n",
    "    PSNR = 10 * tf.math.log(tf.divide(max_value ** 2, MSE)) / tf.math.log(tf.constant(10, dtype=y_pred.dtype))\n",
    "    mean = tf.reduce_mean(PSNR)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uncompiled_automap_model():\n",
    "    \n",
    "    # this one's solid, but I believe we'll need a few hours to train it.\n",
    "    \n",
    "    N = 256\n",
    "    F = N\n",
    "    X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "    # Half-assed data augmentation\n",
    "    noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "    # These layers all halve the spatial dimension (but also each output 256 channels)\n",
    "    conv1 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "    pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "    pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "    pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "    pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4)\n",
    "    pool5 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv5) # shape: (8, 8, F)\n",
    "\n",
    "    conv6 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool5)\n",
    "    pool6 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv6) # shape: (4, 4, F)\n",
    "\n",
    "    # A \"FC-like\" layer for fun before we do upsampling\n",
    "    conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(pool6) # spatial dim: 4\n",
    "\n",
    "    # These transposed convolutions upsample spatial dimension by 2\n",
    "    t_conv1 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(conv7) # spatial dim: 8\n",
    "    t_conv2 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv1) # spatial dim: 16\n",
    "    t_conv3 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv2) # spatial dim: 32\n",
    "    t_conv4 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv3) # spatial dim: 64\n",
    "    t_conv5 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv4) # spatial dim: 128\n",
    "    \n",
    "    Y_pred = tf.keras.layers.Conv2DTranspose(1, 4, strides=2, activation='linear', padding='same')(t_conv5) # spatial dim: 256\n",
    "\n",
    "    model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_compiled_automap_model():\n",
    "    model = load_uncompiled_automap_model()\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(), metrics=[mean_PSNR])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom learning rate schedule\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases as epochs progress.\n",
    "    \"\"\"\n",
    "    learning_rate = 5e-4\n",
    "    if epoch > 2:\n",
    "        learning_rate = 1e-4\n",
    "    if epoch > 3:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 6:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 10:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 15:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 20:\n",
    "        learning_rate = 1e-6\n",
    "    elif epoch > 40:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 80:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 100:\n",
    "        learning_rate = 1e-6\n",
    "\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "        \n",
    "    return learning_rate\n",
    "\n",
    "# Show reconstructions during training\n",
    "\n",
    "def plot_fft_reconstructions(batch, logs):\n",
    "    plot_frequency = 300\n",
    "    \n",
    "    if batch % plot_frequency != 0:\n",
    "        return\n",
    "    \n",
    "    x, y = next(iter(test_dataset)) # always gets the first batch\n",
    "    y = y.numpy()\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    y = np.reshape(y, (-1, 256, 256, 1))\n",
    "    y_pred = np.reshape(y_pred, (-1, 256, 256, 1))\n",
    "    \n",
    "    with file_writer.as_default():\n",
    "        for i in range(min(len(y), 8)):\n",
    "            prediction, ground_truth = y_pred[i:i + 1, ...], y[i:i + 1, ...]\n",
    "            tf.summary.image(\"Test Image {} (Prediction)\".format(i), prediction, max_outputs=1, step=batch)\n",
    "            tf.summary.image(\"Test Image {} (Ground Truth)\".format(i), ground_truth, max_outputs=1, step=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_compiled_automap_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 2)]     0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise (GaussianNois (None, 256, 256, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 256, 128)     2432      \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 128)         16512     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 128)       262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 128)       262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 128, 128, 128)     262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 256, 256, 1)       2049      \n",
      "=================================================================\n",
      "Total params: 2,070,273\n",
      "Trainable params: 2,070,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where logs will be saved\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks to use in various stages of training\n",
    "\n",
    "plot_images_callback = tf.keras.callbacks.LambdaCallback(on_batch_end=plot_fft_reconstructions)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=5, update_freq=500,\n",
    "                                                      profile_batch=0) # workaround for: https://github.com/tensorflow/tensorboard/issues/2084\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25,\n",
    "                              patience=2, min_lr=1e-8)\n",
    "\n",
    "callbacks = [tensorboard_callback, lr_callback, plot_images_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "   1/3125 [..............................] - ETA: 52:21:58 - loss: 0.2832 - mean_PSNR: 6.2562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0529 09:11:17.194385 140586664048384 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (0.419412). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/3125 [=======================>......] - ETA: 5:01 - loss: 0.0395 - mean_PSNR: 15.6033"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7661d3856a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# set to 0 to suppress chatty output and use Tensorboard instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m-> 3510\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m         expand_composites=True)\n\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3508\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m     return nest.pack_sequence_as(\n\u001b[0;32m-> 3510\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m         expand_composites=True)\n\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resource handles are not convertible to numpy.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cpu_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_cpu_nograd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mCPU\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0mbacked\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \"\"\"\n\u001b[0;32m--> 944\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_copy_nograd\u001b[0;34m(self, ctx, device_name)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m       \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    train_dataset, # change to train_dataset!\n",
    "    validation_data=dev_dataset,\n",
    "    verbose=1, # set to 0 to suppress chatty output and use Tensorboard instead\n",
    "    epochs=120,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Uncomment to save model\n",
    "saved_model_path = 'automap_cifar100_big'\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"loss\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_loss\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"mean_PSNR\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_mean_PSNR\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"µ ( PSNR ) \")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a test batch\n",
    "\n",
    "for batch in test_dataset:\n",
    "    x, y = x.numpy(), y.numpy()\n",
    "    y_pred = model.predict(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect output\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    fft_mag = x[i, ..., 0]\n",
    "    fft_ang = x[i, ..., 1]\n",
    "    c = int(cls[i])\n",
    "    reconstruction = y_pred[i, ..., 0]\n",
    "    reconstruction[reconstruction < 0] = 0\n",
    "    reconstruction[reconstruction > 1] = 1\n",
    "    image = y[i, ..., 0]\n",
    "\n",
    "    print('Class: {}'.format(c))\n",
    "    \n",
    "    MSE = utils.signal_processing.mean_square_error(reconstruction, image)\n",
    "    PSNR = utils.signal_processing.PSNR(reconstruction, image, max_value=1.0)\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('Reconstruction (MSE: {:0.5f}, PSNR: {:0.5f})'.format(MSE, PSNR))\n",
    "    utils.plot.imshowgray(reconstruction)\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('FFT (Magnitude)')\n",
    "    utils.plot.imshowfft(fft_mag)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title('Expected reconstruction')\n",
    "    utils.plot.imshowgray(image)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('FFT (Phase)')\n",
    "    utils.plot.imshowgray(fft_ang)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In theory, in TF 2.0 we should be able to see Tensorboard in this notebook with magics:\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs\n",
    "\n",
    "# Clear logs if needed\n",
    "# !rm -rf logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/1l4z7u062nvlhrz/MRI_Kspace.dat\n",
    "# See https://github.com/kmjohnson3/ML4MI_BootCamp/blob/fe9d96cd9f68db073a44f9dc9a015533a008d0a7/ImageReconstruction/CoLab_AutoMap_Recon.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll -h MRI_Kspace.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "#     N = 256\n",
    "#     small_N = N // 4 # after downsampling by 2 twice\n",
    "    \n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=0.001)(X)\n",
    "#     conv_downsample1 = tf.keras.layers.Conv2D(3, (4, 4), strides=(2, 2), activation='tanh', padding='same')(noisy_X)\n",
    "#     conv_downsample2 = tf.keras.layers.Conv2D(3, (4, 4), strides=(1, 1), activation='tanh', padding='same')(conv_downsample1)\n",
    "#     conv_downsample3 = tf.keras.layers.Conv2D(3, (4, 4), strides=(2, 2), activation='tanh', padding='same')(conv_downsample2)\n",
    "#     X1 = tf.keras.layers.Flatten()(conv_downsample3)\n",
    "    \n",
    "#     # Workaround for: ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\n",
    "#     X1_reshaped = tf.keras.layers.Reshape(target_shape=((small_N ** 2) * 2,))(X1)\n",
    "#     X1_DO = tf.keras.layers.Dropout(0.25)(X1_reshaped)\n",
    "    \n",
    "#     fc1 = tf.keras.layers.Dense((small_N ** 2) * 1, activation = 'tanh')(X1_DO)\n",
    "#     fc1_DO = tf.keras.layers.Dropout(0.2)(fc1)\n",
    "    \n",
    "#     fc2 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc1_DO)\n",
    "#     fc2_DO = tf.keras.layers.Dropout(0.2)(fc2)\n",
    "#     fc3 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc2_DO)\n",
    "\n",
    "# #     fc3 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc1_DO)\n",
    "#     X2 = tf.keras.layers.Reshape((small_N, small_N, 1))(fc3)\n",
    "    \n",
    "#     conv1_1 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(0.0001))(X2)\n",
    "#     conv1_2 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(0.0001))(conv1_1)\n",
    "#     conv1_3a = tf.keras.layers.Conv2DTranspose(small_N, 9, activation='relu', padding='same')(conv1_2)\n",
    "#     conv1_3b = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3a)\n",
    "#     conv1_3c = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3b)\n",
    "    \n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, 1, activation = 'linear',padding='same')(conv1_3c)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "    \n",
    "#     return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
