{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use TF 2.0 (on EC2 instance running Deep Learning AMI):\n",
    "# source activate tensorflow_p36\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install tensorflow-gpu==2.0.0-alpha0\n",
    "\n",
    "# But then later decided wanted even newer GPU stuff and in that conda env, ran:\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install --upgrade pip\n",
    "# pip install wrapt --ignore-installed # ran this because had an error\n",
    "# pip install  tf-nightly-gpu-2.0-preview\n",
    "\n",
    "# Result: Successfully installed tf-nightly-gpu-2.0-preview-2.0.0.dev20190527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0-dev20190529\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__) # make sure >= 2.0.0-dev20190527\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cs230_project_utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU usage logging (TF 2.0+)\n",
    "\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (50000, 32, 32)\n",
      "Shape of x_test: (5000, 32, 32)\n",
      "Shape of x_dev: (5000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load cifar 100 (should already be shuffled)\n",
    "(x_train, labels_train), (x_test, labels_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# Convert x_train to float32, grayscale\n",
    "x_train = x_train.astype('float32')\n",
    "x_train =(0.299 * x_train[..., 0] + 0.587 * x_train[..., 1] +  0.114 * x_train[..., 2]) / 255.0\n",
    "\n",
    "# Convert x_test to float32, grayscale \n",
    "x_test = x_test.astype('float32')\n",
    "x_test =(0.299 * x_test[..., 0] + 0.587 * x_test[..., 1] +  0.114 * x_test[..., 2]) / 255.0\n",
    "\n",
    "# Split x_test to create x_dev\n",
    "x_dev, x_test = x_test[:len(x_test) // 2], x_test[len(x_test) // 2:]\n",
    "\n",
    "# Show stats of images\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of x_dev: ' + str(x_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centered_2d_fft(tensor):\n",
    "    ''' \n",
    "    Input\n",
    "        tensor: 2D tensor of shape [height, width]\n",
    "    Returns\n",
    "        fft: centered_2d_fft(tensor) / sqrt(product(tensor.shape)) as dtype tf.complex64\n",
    "    \n",
    "    Inverse: ifft = tf.signal.ifft2d(fft) (if image, use abs(ifft) to view)\n",
    "    \n",
    "    Notes:\n",
    "    \n",
    "    The inverse ffts aren't perfect but pretty close (suspect this is due to casting of dtypes).\n",
    "    Difference b/w image and ifft is imperceptible (visually).\n",
    "    \n",
    "    y = an image\n",
    "    np.allclose(tf.math.real(centered_2d_fft(y0)).numpy(), x0[..., 0], atol=5e-3) -> True\n",
    "    np.allclose(tf.math.imag(centered_2d_fft(y0)).numpy(), x0[..., 1], atol=5e-2) -> True\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    tensor = tf.cast(tensor, tf.complex64)\n",
    "    fft_unshifted = tf.signal.fft2d(tensor)\n",
    "    fft = tf.signal.fftshift(fft_unshifted)\n",
    "    return fft\n",
    "\n",
    "def cifar_parser(sample):\n",
    "    # Returns: (fft, image reconstruction) pairs for automap model\n",
    "    \n",
    "    # Image must be 3-dim\n",
    "    sample = tf.expand_dims(sample, -1)\n",
    "    resized = tf.image.resize(sample, [256, 256])\n",
    "    fft = centered_2d_fft(tf.squeeze(resized))\n",
    "    fft = tf.expand_dims(fft, -1) # tf.signal.fft2d expects 2D input, so we undo the squeeze() from before\n",
    "    \n",
    "    # Separate real and imaginary components into separate channels (models operate on floats)\n",
    "    real = tf.math.real(fft)\n",
    "    imaginary = tf.math.imag(fft)\n",
    "    fft = tf.concat([real, imaginary], axis=-1)\n",
    "    \n",
    "    return fft, resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data.Datasets to preprocess and iterate data efficiently\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.map(cifar_parser)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=4096)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.map(cifar_parser)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "dev_dataset = tf.data.Dataset.from_tensor_slices(x_dev)\n",
    "dev_dataset = dev_dataset.map(cifar_parser)\n",
    "dev_dataset = dev_dataset.shuffle(buffer_size=10)\n",
    "dev_dataset = dev_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A metric to use during training\n",
    "def mean_PSNR(y_true, y_pred):\n",
    "    max_value = 1.0\n",
    "    MSE = tf.reduce_mean(tf.square(y_true - y_pred), axis=[1, 2, 3])\n",
    "    PSNR = 10 * tf.math.log(tf.divide(max_value ** 2, MSE)) / tf.math.log(tf.constant(10, dtype=y_pred.dtype))\n",
    "    mean = tf.reduce_mean(PSNR)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uncompiled_automap_model():\n",
    "\n",
    "    N = 256\n",
    "    X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "    # Paper says 1% multiplicative gaussian noise (this multiplies by 1-centered gaussian\n",
    "    # having stddev = sqrt(rate / (1 - rate)) (here, 0.00032...)\n",
    "    noisy_X = tf.keras.layers.GaussianDropout(rate=1e-7)(X) # spatial dimension: 256\n",
    "    # Note: (we could corrupt when training with cifar, but maybe not other dataset?)\n",
    "\n",
    "    ds1 = tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "    ds1 = tf.keras.layers.MaxPool2D(pool_size=2)(ds1) # (new) downsample to spatial dimension: 128\n",
    "\n",
    "    ds2 = tf.keras.layers.Conv2D(2, (3, 3), strides=(1, 1), activation='relu', padding='same')(ds1)\n",
    "    ds2 = tf.keras.layers.MaxPool2D(pool_size=2)(ds2) # (new) downsample to spatial dimension: 64\n",
    "\n",
    "    ds_flat = tf.keras.layers.Flatten()(ds2)\n",
    "\n",
    "    # fc1 = tf.keras.layers.Dense(8192)(ds_flat)\n",
    "    fc1 = tf.keras.layers.Dense(8192, activation='tanh')(ds_flat)\n",
    "    fc2 = tf.keras.layers.Dense(4096, activation='tanh')(fc1)\n",
    "    fc3 = tf.keras.layers.Dense(4096, activation='tanh')(fc2)\n",
    "\n",
    "    fc_output = tf.keras.layers.Reshape([64, 64, 1])(fc3)\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(256, (5, 5), strides=(1, 1), activation='relu', padding='same')(fc_output)\n",
    "    conv1 = tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=2, activation='relu', padding='same')(conv1) # (new) upsample to spatial dimension 128\n",
    "\n",
    "    # L1 regularization to encourage sparsity\n",
    "    conv2 = tf.keras.layers.Conv2D(256, (5, 5), strides=(1, 1), activation='relu', padding='same',\n",
    "                                       kernel_regularizer=tf.keras.regularizers.l1(1e-4))(conv1)\n",
    "    conv2 = tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=2, activation='relu', padding='same',\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l1(1e-4))(conv2) # (new) upsample to spatial dimension 256\n",
    "\n",
    "    Y_pred = tf.keras.layers.Conv2DTranspose(256, (7, 7), strides=1, activation='relu', padding='same')(conv2) # upsample to spatial dimension 256\n",
    "\n",
    "    model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compiled_automap_model():\n",
    "    model = load_uncompiled_automap_model()\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(), metrics=[mean_PSNR])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom learning rate schedule\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases as epochs progress.\n",
    "    \"\"\"\n",
    "    learning_rate = 2e-4\n",
    "    if epoch > 2:\n",
    "        learning_rate = 1e-4\n",
    "    if epoch > 3:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 6:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 10:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 15:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 20:\n",
    "        learning_rate = 1e-6\n",
    "    elif epoch > 40:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 80:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 100:\n",
    "        learning_rate = 1e-6\n",
    "\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "        \n",
    "    return learning_rate\n",
    "\n",
    "# Show reconstructions during training\n",
    "\n",
    "def plot_fft_reconstructions(batch, logs):\n",
    "    plot_frequency = 100\n",
    "    \n",
    "    if batch % plot_frequency != 0:\n",
    "        return\n",
    "    \n",
    "    x, y = next(iter(test_dataset)) # always gets the first batch\n",
    "    y = y.numpy()\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    y = np.reshape(y, (-1, 256, 256, 1))\n",
    "    y_pred = np.reshape(y_pred, (-1, 256, 256, 1))\n",
    "    \n",
    "    with file_writer.as_default():\n",
    "        for i in range(min(len(y), 8)):\n",
    "            prediction, ground_truth = y_pred[i:i + 1, ...], y[i:i + 1, ...]\n",
    "            tf.summary.image(\"Test Image {} (Prediction)\".format(i), prediction, max_outputs=1, step=batch)\n",
    "            tf.summary.image(\"Test Image {} (Ground Truth)\".format(i), ground_truth, max_outputs=1, step=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_compiled_automap_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 2)]     0         \n",
      "_________________________________________________________________\n",
      "gaussian_dropout (GaussianDr (None, 256, 256, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 256, 256)     4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 2)       4610      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8192)              67117056  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 256)       6656      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 128, 128, 256)     1638656   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 256)     1638656   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 256, 256, 256)     1638656   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 256, 256, 256)     3211520   \n",
      "=================================================================\n",
      "Total params: 125,600,514\n",
      "Trainable params: 125,600,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where logs will be saved\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks to use in various stages of training\n",
    "\n",
    "plot_images_callback = tf.keras.callbacks.LambdaCallback(on_batch_end=plot_fft_reconstructions)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=5, update_freq=500,\n",
    "                                                      profile_batch=0) # workaround for: https://github.com/tensorflow/tensorboard/issues/2084\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25,\n",
    "                              patience=2, min_lr=1e-8)\n",
    "\n",
    "callbacks = [tensorboard_callback, lr_callback, plot_images_callback, reduce_lr_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0530 01:02:03.431354 139672083310336 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (1.894829). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 223/3125 [=>............................] - ETA: 1:10:46 - loss: 0.0287 - mean_PSNR: 17.6940"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    train_dataset, # change to train_dataset!\n",
    "    validation_data=dev_dataset,\n",
    "    verbose=1, # set to 0 to suppress chatty output and use Tensorboard instead\n",
    "    epochs=120,\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=True,  # see if speeds things up\n",
    "    initial_epoch=2 # delete\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Uncomment to save model\n",
    "saved_model_path = 'automap_cifar100_original_with_up_down_sampling'\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"loss\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_loss\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"mean_PSNR\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_mean_PSNR\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Âµ ( PSNR ) \")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a test batch\n",
    "\n",
    "for batch in test_dataset:\n",
    "    x, y = x.numpy(), y.numpy()\n",
    "    y_pred = model.predict(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect output\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    fft_mag = x[i, ..., 0]\n",
    "    fft_ang = x[i, ..., 1]\n",
    "    c = int(cls[i])\n",
    "    reconstruction = y_pred[i, ..., 0]\n",
    "    reconstruction[reconstruction < 0] = 0\n",
    "    reconstruction[reconstruction > 1] = 1\n",
    "    image = y[i, ..., 0]\n",
    "\n",
    "    print('Class: {}'.format(c))\n",
    "    \n",
    "    MSE = utils.signal_processing.mean_square_error(reconstruction, image)\n",
    "    PSNR = utils.signal_processing.PSNR(reconstruction, image, max_value=1.0)\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('Reconstruction (MSE: {:0.5f}, PSNR: {:0.5f})'.format(MSE, PSNR))\n",
    "    utils.plot.imshowgray(reconstruction)\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('FFT (Magnitude)')\n",
    "    utils.plot.imshowfft(fft_mag)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title('Expected reconstruction')\n",
    "    utils.plot.imshowgray(image)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('FFT (Phase)')\n",
    "    utils.plot.imshowgray(fft_ang)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In theory, in TF 2.0 we should be able to see Tensorboard in this notebook with magics:\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs\n",
    "\n",
    "# Clear logs if needed\n",
    "# !rm -rf logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/1l4z7u062nvlhrz/MRI_Kspace.dat\n",
    "# See https://github.com/kmjohnson3/ML4MI_BootCamp/blob/fe9d96cd9f68db073a44f9dc9a015533a008d0a7/ImageReconstruction/CoLab_AutoMap_Recon.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll -h MRI_Kspace.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore these old models (here for ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "#     N = 256\n",
    "#     small_N = N // 4 # after downsampling by 2 twice\n",
    "    \n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-6)(X)\n",
    "#     conv_downsample1 = tf.keras.layers.Conv2D(16, (4, 4), strides=(2, 2), activation='tanh', padding='same')(noisy_X)\n",
    "# #     conv_downsample2 = tf.keras.layers.Conv2D(4, (4, 4), strides=(1, 1), activation='tanh', padding='same')(conv_downsample1)\n",
    "#     conv_downsample3 = tf.keras.layers.Conv2D(2, (4, 4), strides=(2, 2), activation='tanh', padding='same')(conv_downsample1)\n",
    "#     X1 = tf.keras.layers.Flatten()(conv_downsample3)\n",
    "    \n",
    "#     # Workaround for: ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\n",
    "#     X1 = tf.keras.layers.Reshape(target_shape=((small_N ** 2) * 2,))(X1)\n",
    "    \n",
    "#     fc1 = tf.keras.layers.Dense((small_N ** 2) * 1, activation = 'tanh')(X1)\n",
    "#     fc1_DO = tf.keras.layers.Dropout(0.1)(fc1)\n",
    "    \n",
    "#     fc2 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc1_DO)\n",
    "#     fc2_DO = tf.keras.layers.Dropout(0.1)(fc2)\n",
    "\n",
    "#     fc3 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc2_DO)\n",
    "#     X2 = tf.keras.layers.Reshape((small_N, small_N, 1))(fc3)\n",
    "#     conv1_1 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(1e-4))(X2)\n",
    "#     conv1_2 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(1e-4))(conv1_1)\n",
    "#     conv1_3a = tf.keras.layers.Conv2DTranspose(small_N, 9, activation='relu', padding='same')(conv1_2)\n",
    "#     conv1_3b = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3a)\n",
    "#     conv1_3c = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3b)\n",
    "    \n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, 1, activation = 'linear', padding='same')(conv1_3c)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "    \n",
    "#     # this one's solid, but I believe we'll need a few hours to train it.\n",
    "    \n",
    "#     N = 256\n",
    "#     F = N\n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "#     # Half-assed data augmentation\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "#     # These layers all halve the spatial dimension (but also each output 256 channels)\n",
    "#     conv1 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "#     pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "#     conv2 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "#     pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "#     conv3 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "#     pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "#     conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "#     pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "#     conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4)\n",
    "#     pool5 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv5) # shape: (8, 8, F)\n",
    "\n",
    "#     conv6 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool5)\n",
    "#     pool6 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv6) # shape: (4, 4, F)\n",
    "\n",
    "#     # A \"FC-like\" layer for fun before we do upsampling\n",
    "#     conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(pool6) # spatial dim: 4\n",
    "\n",
    "#     # These transposed convolutions upsample spatial dimension by 2\n",
    "#     t_conv1 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(conv7) # spatial dim: 8\n",
    "#     t_conv2 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv1) # spatial dim: 16\n",
    "#     t_conv3 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv2) # spatial dim: 32\n",
    "#     t_conv4 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv3) # spatial dim: 64\n",
    "#     t_conv5 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv4) # spatial dim: 128\n",
    "    \n",
    "#     Y_pred = tf.keras.layers.Conv2DTranspose(1, 4, strides=2, activation='linear', padding='same')(t_conv5) # spatial dim: 256\n",
    "\n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "#     return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no transposed conv, just upsample (first try, guessing too much data lost in middle)\n",
    "\n",
    "# def load_uncompiled_automap_model():\n",
    "\n",
    "#     N = 256\n",
    "#     F = N\n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "#     # Half-assed data augmentation\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "#     # Downsampling\n",
    "\n",
    "#     conv1 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "#     pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "#     conv2 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "#     pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "#     conv3 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "#     pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "#     conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "#     pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "#     conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4)\n",
    "#     pool5 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv5) # shape: (8, 8, F)\n",
    "\n",
    "#     conv6 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool5)\n",
    "#     pool6 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv6) # shape: (4, 4, F)\n",
    "\n",
    "#     # Some pointwise convoluations before finally upsampling\n",
    "\n",
    "#     conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(pool6) # shape: (4, 4, F)\n",
    "#     conv8 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv7) # shape: (4, 4, F)\n",
    "#     conv9 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv8) # shape: (4, 4, F)\n",
    "\n",
    "#     # Upsampling\n",
    "\n",
    "#     conv10 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(conv9)\n",
    "#     pool10 = tf.keras.layers.UpSampling2D(2)(conv10) # shape: (8, 8, F)\n",
    "\n",
    "#     conv11 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool10)\n",
    "#     pool11 = tf.keras.layers.UpSampling2D(2)(conv11) # shape: (16, 16, F)\n",
    "\n",
    "#     conv12 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool11)\n",
    "#     pool12 = tf.keras.layers.UpSampling2D(2)(conv12) # shape: (32, 32, F)\n",
    "\n",
    "#     conv13 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool12)\n",
    "#     pool13 = tf.keras.layers.UpSampling2D(2)(conv13) # shape: (64, 64, F)\n",
    "\n",
    "#     conv14 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool13)\n",
    "#     pool14 = tf.keras.layers.UpSampling2D(2)(conv14) # shape: (128, 128, F)\n",
    "\n",
    "#     conv15 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool14)\n",
    "#     pool15 = tf.keras.layers.UpSampling2D(2)(conv15) # shape: (256, 256, F)\n",
    "\n",
    "#     # One more to smooth things out\n",
    "\n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, (3, 3), strides=(1, 1), activation='linear', padding='same')(pool15)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "\n",
    "#     N = 256\n",
    "#     F = N\n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "#     # Half-assed data augmentation\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "#     # Downsampling\n",
    "\n",
    "#     conv1 = tf.keras.layers.Conv2D(F, (9, 9), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "#     pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "#     conv2 = tf.keras.layers.Conv2D(F, (7, 7), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "#     pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "#     conv3 = tf.keras.layers.Conv2D(F, (5, 5), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "#     pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "#     conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "#     pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "#     # Some pointwise convolutions before finally upsampling\n",
    "\n",
    "#     conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4) # shape: (16, 16, F)\n",
    "#     conv6 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv5) # shape: (16, 16, F)\n",
    "#     conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv6) # shape: (16, 16, F)\n",
    "\n",
    "#     # Upsampling\n",
    "\n",
    "#     t_conv8 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(conv7)\n",
    "#     t_conv9 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv8)\n",
    "#     t_conv10 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv9)\n",
    "#     t_conv11 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv10)\n",
    "    \n",
    "# #     pool8 = tf.keras.layers.UpSampling2D(2)(conv7) # shape: (32, 32, F)\n",
    "# #     conv8 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool8)\n",
    "\n",
    "# #     pool9 = tf.keras.layers.UpSampling2D(2)(conv8) # shape: (64, 64, F)\n",
    "# #     conv9 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool9)\n",
    "\n",
    "# #     pool10 = tf.keras.layers.UpSampling2D(2)(conv9) # shape: (128, 128, F)\n",
    "# #     conv10 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool10)\n",
    "\n",
    "# #     pool11 = tf.keras.layers.UpSampling2D(2)(conv10) # shape: (256, 256, F)\n",
    "# #     conv11 = tf.keras.layers.Conv2D(F, (5, 5), strides=(1, 1), activation='relu', padding='same')(pool11)\n",
    "\n",
    "#     # One more to smooth things out\n",
    "\n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, (2, 2), strides=(1, 1), activation='linear', padding='same')(t_conv11)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "#     return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
