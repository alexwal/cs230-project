{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use TF 2.0 (on EC2 instance running Deep Learning AMI):\n",
    "# source activate tensorflow_p36\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install tensorflow-gpu==2.0.0-alpha0\n",
    "\n",
    "# But then later decided wanted even newer GPU stuff and in that conda env, ran:\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install --upgrade pip\n",
    "# pip install wrapt --ignore-installed # ran this because had an error\n",
    "# pip install  tf-nightly-gpu-2.0-preview\n",
    "\n",
    "# Result: Successfully installed tf-nightly-gpu-2.0-preview-2.0.0.dev20190527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0-dev20190527\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__) # make sure >= 2.0.0-dev20190527\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cs230_project_utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU usage logging (TF 2.0+)\n",
    "\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (50000, 32, 32)\n",
      "Shape of x_test: (5000, 32, 32)\n",
      "Shape of x_dev: (5000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load cifar 100 (should already be shuffled)\n",
    "(x_train, labels_train), (x_test, labels_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# Convert x_train to float32, grayscale\n",
    "x_train = x_train.astype('float32')\n",
    "x_train =(0.299 * x_train[..., 0] + 0.587 * x_train[..., 1] +  0.114 * x_train[..., 2]) / 255.0\n",
    "\n",
    "# Convert x_test to float32, grayscale \n",
    "x_test = x_test.astype('float32')\n",
    "x_test =(0.299 * x_test[..., 0] + 0.587 * x_test[..., 1] +  0.114 * x_test[..., 2]) / 255.0\n",
    "\n",
    "# Split x_test to create x_dev\n",
    "x_dev, x_test = x_test[:len(x_test) // 2], x_test[len(x_test) // 2:]\n",
    "\n",
    "# Show stats of images\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of x_dev: ' + str(x_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_2d_scaled_and_centered(tensor):\n",
    "    ''' \n",
    "    Input\n",
    "        tensor: 2D tensor of shape [height, width]\n",
    "    Returns\n",
    "        fft: centered_2d_fft(tensor) / sqrt(product(tensor.shape)) as dtype tf.complex64\n",
    "        \n",
    "    Tested and np.allclose(fft, numpy_fft, atol=1e-5) returns True, where\n",
    "    numpy_fft = np.abs(utils.signal_processing.fft_2D_centered(tensor)).\n",
    "    \n",
    "    '''\n",
    "    complex_valued = tf.cast(tf.squeeze(tensor), tf.complex64)\n",
    "    fft = tf.signal.fft2d(complex_valued)\n",
    "    scale = tf.math.sqrt(tf.reduce_prod(tf.cast(fft.shape, tf.float32)))\n",
    "    fft_scaled = fft / tf.cast(scale, tf.complex64)\n",
    "    centered_fft = tf.signal.fftshift(fft_scaled)\n",
    "    return centered_fft\n",
    "\n",
    "def cifar_parser(sample):\n",
    "    # Returns: (fft, image reconstruction) pairs for automap model\n",
    "    \n",
    "    # Image must be 3-dim\n",
    "    sample = tf.expand_dims(sample, -1)\n",
    "    resized = tf.image.resize(sample, [256, 256])\n",
    "    fft = fft_2d_scaled_and_centered(tf.squeeze(resized))\n",
    "    fft = tf.expand_dims(fft, -1) # tf.signal.fft2d expects 2D input, so we undo the squeeze() from before\n",
    "    \n",
    "    # Separate magnitude and phase into separate dimensions\n",
    "    magnitude = tf.math.abs(fft)\n",
    "    phase = tf.math.angle(fft)\n",
    "    fft = tf.concat([magnitude, phase], axis=-1)\n",
    "    \n",
    "    return fft, resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data.Datasets to preprocess and iterate data efficiently\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset = train_dataset.map(cifar_parser)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=4096)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "test_dataset = test_dataset.map(cifar_parser)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "dev_dataset = tf.data.Dataset.from_tensor_slices(x_dev)\n",
    "dev_dataset = dev_dataset.map(cifar_parser)\n",
    "dev_dataset = dev_dataset.shuffle(buffer_size=128)\n",
    "dev_dataset = dev_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A metric to use during training\n",
    "def mean_PSNR(y_true, y_pred):\n",
    "    max_value = 1.0\n",
    "    MSE = tf.reduce_mean(tf.square(y_true - y_pred), axis=[1, 2, 3])\n",
    "    PSNR = 10 * tf.math.log(tf.divide(max_value ** 2, MSE)) / tf.math.log(tf.constant(10, dtype=y_pred.dtype))\n",
    "    mean = tf.reduce_mean(PSNR)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uncompiled_automap_model():\n",
    "    \n",
    "    # this one's solid, but I believe we'll need a few hours to train it.\n",
    "    \n",
    "    N = 256\n",
    "    F = N // 2\n",
    "    X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "    # Half-assed data augmentation\n",
    "    noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "    # These layers all halve the spatial dimension (but also each output 256 channels)\n",
    "    conv1 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "    pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "    pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "    pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "    pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4)\n",
    "    pool5 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv5) # shape: (8, 8, F)\n",
    "\n",
    "    conv6 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool5)\n",
    "    pool6 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv6) # shape: (4, 4, F)\n",
    "\n",
    "    # A \"FC-like\" layer for fun before we do upsampling\n",
    "    conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(pool6) # spatial dim: 4\n",
    "\n",
    "    # These transposed convolutions upsample spatial dimension by 2\n",
    "    t_conv1 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(conv7) # spatial dim: 8\n",
    "    t_conv2 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv1) # spatial dim: 16\n",
    "    t_conv3 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv2) # spatial dim: 32\n",
    "    t_conv4 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv3) # spatial dim: 64\n",
    "    t_conv5 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv4) # spatial dim: 128\n",
    "    \n",
    "    Y_pred = tf.keras.layers.Conv2DTranspose(1, 4, strides=2, activation='linear', padding='same')(t_conv5) # spatial dim: 256\n",
    "\n",
    "    model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_compiled_automap_model():\n",
    "    model = load_uncompiled_automap_model()\n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(), metrics=[mean_PSNR])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom learning rate schedule\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases as epochs progress.\n",
    "    \"\"\"\n",
    "    learning_rate = 5e-4\n",
    "    if epoch > 3:\n",
    "        learning_rate = 1e-4\n",
    "    elif epoch > 6:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 10:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 15:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 20:\n",
    "        learning_rate = 1e-6\n",
    "    elif epoch > 40:\n",
    "        learning_rate = 1e-5\n",
    "    elif epoch > 80:\n",
    "        learning_rate = 5e-5\n",
    "    elif epoch > 100:\n",
    "        learning_rate = 1e-6\n",
    "\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "        \n",
    "    return learning_rate\n",
    "\n",
    "# Show reconstructions during training\n",
    "\n",
    "def plot_fft_reconstructions(batch, logs):\n",
    "    plot_frequency = 100\n",
    "    \n",
    "    if batch % plot_frequency != 0:\n",
    "        return\n",
    "    \n",
    "    x, y = next(iter(test_dataset)) # always gets the first batch\n",
    "    y = y.numpy()\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    y = np.reshape(y, (-1, 256, 256, 1))\n",
    "    y_pred = np.reshape(y_pred, (-1, 256, 256, 1))\n",
    "    \n",
    "    with file_writer.as_default():\n",
    "        for i in range(min(len(y), 8)):\n",
    "            prediction, ground_truth = y_pred[i:i + 1, ...], y[i:i + 1, ...]\n",
    "            tf.summary.image(\"Test Image {} (Prediction)\".format(i), prediction, max_outputs=1, step=batch)\n",
    "            tf.summary.image(\"Test Image {} (Ground Truth)\".format(i), ground_truth, max_outputs=1, step=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_compiled_automap_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 256, 256, 2)]     0         \n",
      "_________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNo (None, 256, 256, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 256, 256, 128)     2432      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_12 (Averag (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_13 (Averag (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_16 (Averag (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_17 (Averag (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 4, 4, 128)         16512     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 32, 32, 128)       262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 64, 64, 128)       262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 128, 128, 128)     262272    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 256, 256, 1)       2049      \n",
      "=================================================================\n",
      "Total params: 2,070,273\n",
      "Trainable params: 2,070,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where logs will be saved\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks to use in various stages of training\n",
    "\n",
    "plot_images_callback = tf.keras.callbacks.LambdaCallback(on_batch_end=plot_fft_reconstructions)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=5, update_freq=500,\n",
    "                                                      profile_batch=0) # workaround for: https://github.com/tensorflow/tensorboard/issues/2084\n",
    "\n",
    "callbacks = [tensorboard_callback, lr_callback, plot_images_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  1/313 [..............................] - ETA: 24:42 - loss: 0.3203 - mean_PSNR: 5.3693"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0529 09:03:21.623058 139627066590976 callbacks.py:257] Method (on_train_batch_end) is slow compared to the batch update (0.409698). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/313 [============================>.] - ETA: 0s - loss: 0.0710 - mean_PSNR: 14.5535"
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    dev_dataset, # change to train_dataset!\n",
    "    validation_data=test_dataset,\n",
    "    verbose=1, # set to 0 to suppress chatty output and use Tensorboard instead\n",
    "    epochs=120,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Uncomment to save model\n",
    "# saved_model_path = 'automap_cifar100'\n",
    "# model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"loss\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_loss\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"mean_PSNR\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_mean_PSNR\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"µ ( PSNR ) \")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a test batch\n",
    "\n",
    "for batch in test_dataset:\n",
    "    x, y = x.numpy(), y.numpy()\n",
    "    y_pred = model.predict(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inspect output\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    fft_mag = x[i, ..., 0]\n",
    "    fft_ang = x[i, ..., 1]\n",
    "    c = int(cls[i])\n",
    "    reconstruction = y_pred[i, ..., 0]\n",
    "    reconstruction[reconstruction < 0] = 0\n",
    "    reconstruction[reconstruction > 1] = 1\n",
    "    image = y[i, ..., 0]\n",
    "\n",
    "    print('Class: {}'.format(c))\n",
    "    \n",
    "    MSE = utils.signal_processing.mean_square_error(reconstruction, image)\n",
    "    PSNR = utils.signal_processing.PSNR(reconstruction, image, max_value=1.0)\n",
    "\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.title('Reconstruction (MSE: {:0.5f}, PSNR: {:0.5f})'.format(MSE, PSNR))\n",
    "    utils.plot.imshowgray(reconstruction)\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.title('FFT (Magnitude)')\n",
    "    utils.plot.imshowfft(fft_mag)\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.title('Expected reconstruction')\n",
    "    utils.plot.imshowgray(image)\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.title('FFT (Phase)')\n",
    "    utils.plot.imshowgray(fft_ang)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In theory, in TF 2.0 we should be able to see Tensorboard in this notebook with magics:\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs\n",
    "\n",
    "# Clear logs if needed\n",
    "# !rm -rf logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/1l4z7u062nvlhrz/MRI_Kspace.dat\n",
    "# See https://github.com/kmjohnson3/ML4MI_BootCamp/blob/fe9d96cd9f68db073a44f9dc9a015533a008d0a7/ImageReconstruction/CoLab_AutoMap_Recon.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll -h MRI_Kspace.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "#     N = 256\n",
    "#     small_N = N // 4 # after downsampling by 2 twice\n",
    "    \n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=0.001)(X)\n",
    "#     conv_downsample1 = tf.keras.layers.Conv2D(3, (4, 4), strides=(2, 2), activation='tanh', padding='same')(noisy_X)\n",
    "#     conv_downsample2 = tf.keras.layers.Conv2D(3, (4, 4), strides=(1, 1), activation='tanh', padding='same')(conv_downsample1)\n",
    "#     conv_downsample3 = tf.keras.layers.Conv2D(3, (4, 4), strides=(2, 2), activation='tanh', padding='same')(conv_downsample2)\n",
    "#     X1 = tf.keras.layers.Flatten()(conv_downsample3)\n",
    "    \n",
    "#     # Workaround for: ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\n",
    "#     X1_reshaped = tf.keras.layers.Reshape(target_shape=((small_N ** 2) * 2,))(X1)\n",
    "#     X1_DO = tf.keras.layers.Dropout(0.25)(X1_reshaped)\n",
    "    \n",
    "#     fc1 = tf.keras.layers.Dense((small_N ** 2) * 1, activation = 'tanh')(X1_DO)\n",
    "#     fc1_DO = tf.keras.layers.Dropout(0.2)(fc1)\n",
    "    \n",
    "#     fc2 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc1_DO)\n",
    "#     fc2_DO = tf.keras.layers.Dropout(0.2)(fc2)\n",
    "#     fc3 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc2_DO)\n",
    "\n",
    "# #     fc3 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc1_DO)\n",
    "#     X2 = tf.keras.layers.Reshape((small_N, small_N, 1))(fc3)\n",
    "    \n",
    "#     conv1_1 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(0.0001))(X2)\n",
    "#     conv1_2 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(0.0001))(conv1_1)\n",
    "#     conv1_3a = tf.keras.layers.Conv2DTranspose(small_N, 9, activation='relu', padding='same')(conv1_2)\n",
    "#     conv1_3b = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3a)\n",
    "#     conv1_3c = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3b)\n",
    "    \n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, 1, activation = 'linear',padding='same')(conv1_3c)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "    \n",
    "#     return model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
