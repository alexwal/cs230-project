{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use TF 2.0 (on EC2 instance running Deep Learning AMI):\n",
    "# source activate tensorflow_p36\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install tensorflow-gpu==2.0.0-alpha0\n",
    "\n",
    "# But then later decided wanted even newer GPU stuff and \"in that conda env, ran:\n",
    "# pip uninstall tensorflow-gpu\n",
    "# pip install --upgrade pip\n",
    "# pip install wrapt --ignore-installed # ran this because had an error\n",
    "# pip install  tf-nightly-gpu-2.0-preview\n",
    "\n",
    "# Result: Successfully installed tf-nightly-gpu-2.0-preview-2.0.0.dev20190531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0-dev20190531\n"
     ]
    }
   ],
   "source": [
    "from packaging import version\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__) # make sure >= 2.0.0-dev20190527\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cs230_project_utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU usage logging (TF 2.0+)\n",
    "\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load cifar 100 (should already be shuffled)\n",
    "# (x_train, labels_train), (x_test, labels_test) = tf.keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# # Convert x_train to float32, grayscale\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_train =(0.299 * x_train[..., 0] + 0.587 * x_train[..., 1] +  0.114 * x_train[..., 2]) / 255.0\n",
    "\n",
    "# # Convert x_test to float32, grayscale \n",
    "# x_test = x_test.astype('float32')\n",
    "# x_test =(0.299 * x_test[..., 0] + 0.587 * x_test[..., 1] +  0.114 * x_test[..., 2]) / 255.0\n",
    "\n",
    "# # Split x_test to create x_dev\n",
    "# x_dev, x_test = x_test[:len(x_test) // 2], x_test[len(x_test) // 2:]\n",
    "\n",
    "# # Show stats of images\n",
    "# print('Shape of x_train: ' + str(x_train.shape))\n",
    "# print('Shape of x_test: ' + str(x_test.shape))\n",
    "# print('Shape of x_dev: ' + str(x_dev.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def centered_2d_fft(tensor):\n",
    "#     ''' \n",
    "#     Input\n",
    "#         tensor: 2D tensor of shape [height, width]\n",
    "#     Returns\n",
    "#         fft: centered_2d_fft(tensor) / sqrt(product(tensor.shape)) as dtype tf.complex64\n",
    "    \n",
    "#     Inverse: ifft = tf.signal.ifft2d(fft) (if image, use abs(ifft) to view)\n",
    "    \n",
    "#     Notes:\n",
    "    \n",
    "#     The inverse ffts aren't perfect but pretty close (suspect this is due to casting of dtypes).\n",
    "#     Difference b/w image and ifft is imperceptible (visually).\n",
    "    \n",
    "#     y = an image\n",
    "#     np.allclose(tf.math.real(centered_2d_fft(y0)).numpy(), x0[..., 0], atol=5e-3) -> True\n",
    "#     np.allclose(tf.math.imag(centered_2d_fft(y0)).numpy(), x0[..., 1], atol=5e-2) -> True\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     tensor = tf.cast(tensor, tf.complex64)\n",
    "#     fft_unshifted = tf.signal.fft2d(tensor)\n",
    "#     fft = tf.signal.fftshift(fft_unshifted)\n",
    "#     return fft\n",
    "\n",
    "# def cifar_parser(sample):\n",
    "#     # Returns: (fft, image reconstruction) pairs for automap model\n",
    "    \n",
    "#     # Image must be 3-dim\n",
    "#     sample = tf.expand_dims(sample, -1)\n",
    "#     resized = tf.image.resize(sample, [256, 256])\n",
    "#     fft = centered_2d_fft(tf.squeeze(resized))\n",
    "#     fft = tf.expand_dims(fft, -1) # tf.signal.fft2d expects 2D input, so we undo the squeeze() from before\n",
    "    \n",
    "#     # Separate real and imaginary components into separate channels (models operate on floats)\n",
    "#     real = tf.math.real(fft)\n",
    "#     imaginary = tf.math.imag(fft)\n",
    "#     fft = tf.concat([real, imaginary], axis=-1)\n",
    "    \n",
    "#     return fft, resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_locations, batch_size, buffer_size, include_all_parsed_features):\n",
    "    '''\n",
    "    Returns iterator of automap data located in `data_locations`.\n",
    "    \n",
    "    data_locations:  A string, a list of strings, or a `tf.Tensor` of string type\n",
    "    (scalar or vector), representing the filename glob (i.e. shell wildcard)\n",
    "    pattern(s) that will be matched.\n",
    "    '''\n",
    "    filenames = tf.data.TFRecordDataset.list_files(data_locations)\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "    # Use `tf.parse_single_example()` to extract data from a `tf.Example`\n",
    "    # protocol buffer, and perform any additional per-example processing.\n",
    "    def parser(record):\n",
    "        keys_to_features = {\n",
    "            \"path\": tf.io.FixedLenFeature((), tf.string, \"\"),\n",
    "            \"sequence_index\": tf.io.FixedLenFeature((), tf.int64, -1),\n",
    "            \"fft\": tf.io.FixedLenFeature((), tf.string, ''),\n",
    "            \"image\": tf.io.FixedLenFeature((), tf.string, ''),\n",
    "            \"dimension\": tf.io.FixedLenFeature((), tf.int64, -1),\n",
    "            \"class\": tf.io.FixedLenFeature((), tf.int64, -1)\n",
    "        }\n",
    "        parsed = tf.io.parse_single_example(record, keys_to_features)\n",
    "        \n",
    "        # Perform additional preprocessing on the parsed data.\n",
    "        parsed['fft'] = tf.io.decode_raw(parsed['fft'], out_type=tf.float32)\n",
    "        parsed['image'] = tf.io.decode_raw(parsed['image'], out_type=tf.float32)\n",
    "        \n",
    "        parsed['fft'] = tf.reshape(parsed['fft'], [parsed['dimension'], parsed['dimension'], 2])\n",
    "        parsed['image'] = tf.reshape(parsed['image'], [parsed['dimension'], parsed['dimension'], 1])\n",
    "        \n",
    "        if include_all_parsed_features:\n",
    "            return parsed\n",
    "        \n",
    "        # We only want input and expected output during training stage (X, Y)\n",
    "        return parsed['fft'], parsed['image']\n",
    "    \n",
    "    # Use `Dataset.map()` to build a pair of a feature dictionary and a label\n",
    "    # tensor for each example.\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Each element of `dataset` is tuple containing a dictionary of features\n",
    "    # (in which each value is a batch of values for that feature), and a batch of\n",
    "    # labels.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.data.Datasets to preprocess and iterate data efficiently\n",
    "\n",
    "# include class_0?\n",
    "test_data_locations = ['/home/ubuntu/cs230/data/tfrecords/test/class_0/*.tfrecord'] # only bad for test\n",
    "dev_data_locations = ['/home/ubuntu/cs230/data/tfrecords/dev/class_0/*.tfrecord'] # only bad for dev\n",
    "train_data_locations = ['/home/ubuntu/cs230/data/tfrecords/*/class_1/*.tfrecord'] # only good for train (note: first * is weird but prev had separated out 0, 1 for dev and test too but should train on all 1 classes and test on rest)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "test_dataset = load_dataset(test_data_locations, batch_size=batch_size, buffer_size=1, include_all_parsed_features=False) # no need to shuffle test and dev\n",
    "dev_dataset = load_dataset(dev_data_locations, batch_size=batch_size, buffer_size=1, include_all_parsed_features=False)\n",
    "train_dataset = load_dataset(train_data_locations, batch_size=batch_size, buffer_size=512, include_all_parsed_features=False) # good to shuffle train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First batch of each dataset to be used in plotting images periodically to tensorboard\n",
    "\n",
    "first_test_batch = next(iter(test_dataset))\n",
    "first_dev_batch = next(iter(dev_dataset))\n",
    "first_train_batch = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A metric to use during training\n",
    "def mean_PSNR(y_true, y_pred):\n",
    "    max_value = 1.0\n",
    "    MSE = tf.reduce_mean(tf.square(y_true - y_pred), axis=[1, 2, 3])\n",
    "    PSNR = 10 * tf.math.log(tf.divide(max_value ** 2, MSE)) / tf.math.log(tf.constant(10, dtype=y_pred.dtype))\n",
    "    mean = tf.reduce_mean(PSNR)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_uncompiled_automap_model():\n",
    "\n",
    "    N = 256\n",
    "    X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "    # Paper says 1% multiplicative gaussian noise (this multiplies by 1-centered gaussian\n",
    "    # having stddev = sqrt(rate / (1 - rate)) (here, 0.00032...)\n",
    "    noisy_X = tf.keras.layers.GaussianDropout(rate=1e-7)(X) # spatial dimension: 256\n",
    "    # Note: (we could corrupt when training with cifar, but maybe not other dataset?)\n",
    "\n",
    "    ds1 = tf.keras.layers.Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "    ds1 = tf.keras.layers.MaxPool2D(pool_size=2)(ds1) # (new) downsample to spatial dimension: 128\n",
    "\n",
    "    ds2 = tf.keras.layers.Conv2D(2, (3, 3), strides=(1, 1), activation='relu', padding='same')(ds1)\n",
    "    ds2 = tf.keras.layers.MaxPool2D(pool_size=2)(ds2) # (new) downsample to spatial dimension: 64\n",
    "\n",
    "    ds_flat = tf.keras.layers.Flatten()(ds2)\n",
    "\n",
    "    fc1 = tf.keras.layers.Dense(4096, activation='tanh')(ds_flat)\n",
    "    fc1 = tf.keras.layers.Dropout(0.05)(fc1)\n",
    "    fc2 = tf.keras.layers.Dense(4096, activation='tanh')(fc1)\n",
    "    fc2 = tf.keras.layers.Dropout(0.05)(fc2)\n",
    "    fc3 = tf.keras.layers.Dense(4096, activation='tanh')(fc2)\n",
    "\n",
    "    fc_output = tf.keras.layers.Reshape([64, 64, 1])(fc3)\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(256, (5, 5), strides=(1, 1), activation='relu', padding='same')(fc_output)\n",
    "    conv1 = tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=2, activation='relu', padding='same')(conv1) # (new) upsample to spatial dimension 128\n",
    "\n",
    "    # L1 regularization to encourage sparsity\n",
    "    conv2 = tf.keras.layers.Conv2D(256, (5, 5), strides=(1, 1), activation='relu', padding='same',\n",
    "                                       kernel_regularizer=tf.keras.regularizers.l1(1e-4))(conv1)\n",
    "    conv2 = tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=2, activation='relu', padding='same',\n",
    "                                        kernel_regularizer=tf.keras.regularizers.l1(1e-4))(conv2) # (new) upsample to spatial dimension 256\n",
    "\n",
    "    Y_pred = tf.keras.layers.Conv2DTranspose(1, (7, 7), strides=1, activation='relu', padding='same')(conv2) # upsample to spatial dimension 256\n",
    "\n",
    "    model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compiled_automap_model():\n",
    "    multi_gpu = False\n",
    "    # Distribute training across GPUs (each GPU receives identical updates to weights but different batches w/\n",
    "    # mirrored strategy). Restricts callbacks we can use\n",
    "    if multi_gpu:\n",
    "        mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "        with mirrored_strategy.scope():\n",
    "            model = load_uncompiled_automap_model()\n",
    "            model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(), metrics=[mean_PSNR])\n",
    "    else:\n",
    "        model = load_uncompiled_automap_model()\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(), metrics=[mean_PSNR])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom learning rate schedule\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases as epochs progress.\n",
    "    \"\"\"\n",
    "    if 0 <= epoch < 100:\n",
    "        learning_rate = 1e-4\n",
    "    elif 100 <= epoch < 200:\n",
    "        learning_rate = 5e-5\n",
    "    elif 200 <= epoch < 400:\n",
    "        learning_rate = 2.55e-5\n",
    "    elif 400 <= epoch < 600:\n",
    "        learning_rate = 1e-5\n",
    "    elif 600 <= epoch < 700:\n",
    "        learning_rate = 2.5e-5\n",
    "    elif 700 <= epoch < 800:\n",
    "        learning_rate = 1e-5\n",
    "    elif 800 <= epoch < 900:\n",
    "        learning_rate = 1e-6\n",
    "    else:\n",
    "        learning_rate = 1e-7\n",
    "\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "        \n",
    "    return learning_rate\n",
    "\n",
    "# Show reconstructions during training\n",
    "\n",
    "def plot_fft_reconstructions(batch, logs):\n",
    "    plot_frequency = 100\n",
    "    \n",
    "    if batch % plot_frequency != 0:\n",
    "        return\n",
    "    \n",
    "    batches = [(first_test_batch, 'Test'), (first_dev_batch, 'Dev'), (first_train_batch, 'Train')]\n",
    "    \n",
    "    for dataset_batch, name in batches:\n",
    "        x, y = dataset_batch\n",
    "        y = y.numpy()\n",
    "        y_pred = model.predict(x)\n",
    "\n",
    "        with file_writer.as_default():\n",
    "            for i in range(min(len(y), 8)):\n",
    "                prediction, ground_truth = y_pred[i:i + 1, ...], y[i:i + 1, ...]\n",
    "                tf.summary.image(\"{} Image {} (Prediction)\".format(name, i), prediction, max_outputs=1, step=batch)\n",
    "                tf.summary.image(\"{} Image {} (Ground Truth)\".format(name, i), ground_truth, max_outputs=1, step=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_compiled_automap_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 2)]     0         \n",
      "_________________________________________________________________\n",
      "gaussian_dropout (GaussianDr (None, 256, 256, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 256, 256)     4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 2)       4610      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 256)       6656      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 128, 128, 256)     1638656   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 128, 256)     1638656   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 256, 256, 256)     1638656   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 256, 256, 1)       12545     \n",
      "=================================================================\n",
      "Total params: 72,065,795\n",
      "Trainable params: 72,065,795\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define where logs will be saved\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks to use in various stages of training\n",
    "\n",
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintAndLogLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('learning rate (end of epoch)', data=model.optimizer.lr.numpy(), step=epoch)\n",
    "        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "                                                          model.optimizer.lr.numpy()))\n",
    "\n",
    "plot_images_callback = tf.keras.callbacks.LambdaCallback(on_batch_end=plot_fft_reconstructions)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=2, update_freq=500,\n",
    "                                                      profile_batch=0) # workaround for: https://github.com/tensorflow/tensorboard/issues/2084\n",
    "\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25,\n",
    "                              patience=2, min_lr=1e-8)\n",
    "\n",
    "callbacks = [tensorboard_callback, lr_callback, plot_images_callback, reduce_lr_callback, PrintAndLogLR()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "      1/Unknown - 12s 12s/step - loss: 3.5782 - mean_PSNR: 15.3906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0531 16:25:43.053510 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.610075). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     26/Unknown - 33s 1s/step - loss: 3.1906 - mean_PSNR: 15.6361\n",
      "Learning rate for epoch 1 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 40s 2s/step - loss: 3.1906 - mean_PSNR: 15.6361 - val_loss: 0.0000e+00 - val_mean_PSNR: 0.0000e+00\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:26:12.676192 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.969574). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 2.4537 - mean_PSNR: 16.5827\n",
      "Learning rate for epoch 2 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 694ms/step - loss: 2.4407 - mean_PSNR: 16.5766 - val_loss: 2.0851 - val_mean_PSNR: 17.7505\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:26:30.758956 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.006253). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 1.8003 - mean_PSNR: 18.0366\n",
      "Learning rate for epoch 3 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 23s 896ms/step - loss: 1.7890 - mean_PSNR: 18.1023 - val_loss: 1.4869 - val_mean_PSNR: 18.9855\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:26:54.089313 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.084960). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 1.2493 - mean_PSNR: 20.4728\n",
      "Learning rate for epoch 4 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 1.2403 - mean_PSNR: 20.4565 - val_loss: 0.9979 - val_mean_PSNR: 19.5033\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:27:12.251622 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.103189). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.8073 - mean_PSNR: 20.6852\n",
      "Learning rate for epoch 5 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.8002 - mean_PSNR: 20.6663 - val_loss: 0.6099 - val_mean_PSNR: 19.4333\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:27:35.687218 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.100067). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.4646 - mean_PSNR: 20.7431\n",
      "Learning rate for epoch 6 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.4594 - mean_PSNR: 20.7267 - val_loss: 0.3206 - val_mean_PSNR: 19.4113\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:27:53.865837 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.088442). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.2208 - mean_PSNR: 20.7860\n",
      "Learning rate for epoch 7 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.2174 - mean_PSNR: 20.7685 - val_loss: 0.1290 - val_mean_PSNR: 19.7249\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:28:17.275351 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.079369). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0756 - mean_PSNR: 20.8559\n",
      "Learning rate for epoch 8 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0741 - mean_PSNR: 20.8373 - val_loss: 0.0363 - val_mean_PSNR: 20.0382\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:28:35.418703 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.069566). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0248 - mean_PSNR: 20.9768\n",
      "Learning rate for epoch 9 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0246 - mean_PSNR: 20.9647 - val_loss: 0.0207 - val_mean_PSNR: 20.1206\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:28:58.828235 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.072067). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0166 - mean_PSNR: 21.1264\n",
      "Learning rate for epoch 10 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0166 - mean_PSNR: 21.1133 - val_loss: 0.0167 - val_mean_PSNR: 20.5728\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:29:16.965355 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.090769). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0144 - mean_PSNR: 21.2698\n",
      "Learning rate for epoch 11 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0144 - mean_PSNR: 21.2531 - val_loss: 0.0158 - val_mean_PSNR: 20.5408\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:29:40.286781 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.068640). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0136 - mean_PSNR: 21.3354\n",
      "Learning rate for epoch 12 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0136 - mean_PSNR: 21.3205 - val_loss: 0.0153 - val_mean_PSNR: 20.5619\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:29:58.435303 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.088176). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0131 - mean_PSNR: 21.3792\n",
      "Learning rate for epoch 13 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 23s 897ms/step - loss: 0.0131 - mean_PSNR: 21.3666 - val_loss: 0.0150 - val_mean_PSNR: 20.5720\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:30:21.773927 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.082889). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0128 - mean_PSNR: 21.4133\n",
      "Learning rate for epoch 14 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0128 - mean_PSNR: 21.4025 - val_loss: 0.0147 - val_mean_PSNR: 20.6131\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:30:39.940536 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.086353). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0126 - mean_PSNR: 21.4434\n",
      "Learning rate for epoch 15 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0126 - mean_PSNR: 21.4307 - val_loss: 0.0145 - val_mean_PSNR: 20.7281\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:31:03.264027 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.078328). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0121 - mean_PSNR: 21.6368\n",
      "Learning rate for epoch 16 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 695ms/step - loss: 0.0121 - mean_PSNR: 21.6227 - val_loss: 0.0140 - val_mean_PSNR: 20.8568\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:31:21.379764 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.087874). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0118 - mean_PSNR: 21.7164\n",
      "Learning rate for epoch 17 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 23s 897ms/step - loss: 0.0118 - mean_PSNR: 21.7028 - val_loss: 0.0138 - val_mean_PSNR: 20.9048\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:31:44.785100 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.109998). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0116 - mean_PSNR: 21.7821\n",
      "Learning rate for epoch 18 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0116 - mean_PSNR: 21.7680 - val_loss: 0.0135 - val_mean_PSNR: 20.9929\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:32:02.899251 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.097245). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0115 - mean_PSNR: 21.8175\n",
      "Learning rate for epoch 19 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0115 - mean_PSNR: 21.8033 - val_loss: 0.0133 - val_mean_PSNR: 21.0470\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:32:26.307304 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.087820). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0114 - mean_PSNR: 21.8431\n",
      "Learning rate for epoch 20 is 9.999999747378752e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0114 - mean_PSNR: 21.8305 - val_loss: 0.0131 - val_mean_PSNR: 21.0950\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 16:32:44.410204 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.085594). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.2270\n",
      "Learning rate for epoch 229 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 901ms/step - loss: 0.0042 - mean_PSNR: 25.2202 - val_loss: 0.0075 - val_mean_PSNR: 22.3667\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:45:00.251304 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.188171). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0041 - mean_PSNR: 25.3555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:45:00.884120 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.594119). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.2403\n",
      "Learning rate for epoch 230 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0042 - mean_PSNR: 25.2333 - val_loss: 0.0075 - val_mean_PSNR: 22.3601\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:45:18.435655 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.184987). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0042 - mean_PSNR: 25.3614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:45:19.055371 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.592526). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.2492\n",
      "Learning rate for epoch 231 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 901ms/step - loss: 0.0042 - mean_PSNR: 25.2421 - val_loss: 0.0075 - val_mean_PSNR: 22.3629\n",
      "Epoch 232/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:45:41.874028 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.166266). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0042 - mean_PSNR: 25.3744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:45:42.494245 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.583165). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.2520\n",
      "Learning rate for epoch 232 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0042 - mean_PSNR: 25.2453 - val_loss: 0.0075 - val_mean_PSNR: 22.3582\n",
      "Epoch 233/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:46:00.043819 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.152881). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0041 - mean_PSNR: 25.3916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:46:00.672359 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.576473). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.2638\n",
      "Learning rate for epoch 233 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0042 - mean_PSNR: 25.2571 - val_loss: 0.0075 - val_mean_PSNR: 22.3659\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:46:23.432605 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.158401). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0041 - mean_PSNR: 25.3914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:46:24.049480 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.579233). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.2701\n",
      "Learning rate for epoch 234 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0042 - mean_PSNR: 25.2633 - val_loss: 0.0075 - val_mean_PSNR: 22.3614\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:46:41.578124 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.172988). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0041 - mean_PSNR: 25.3973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:46:42.196158 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.586527). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.2839\n",
      "Learning rate for epoch 235 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0042 - mean_PSNR: 25.2766 - val_loss: 0.0075 - val_mean_PSNR: 22.3609\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:47:04.982972 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.187360). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0041 - mean_PSNR: 25.4151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:47:05.600095 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.594109). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.2918\n",
      "Learning rate for epoch 236 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0042 - mean_PSNR: 25.2845 - val_loss: 0.0075 - val_mean_PSNR: 22.3638\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:47:23.136050 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.172014). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0041 - mean_PSNR: 25.3986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:47:23.752235 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.586039). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.3054\n",
      "Learning rate for epoch 237 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.0042 - mean_PSNR: 25.2983 - val_loss: 0.0075 - val_mean_PSNR: 22.3544\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:47:46.546662 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.172360). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0041 - mean_PSNR: 25.4180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:47:47.164553 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.586213). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.3162\n",
      "Learning rate for epoch 238 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0042 - mean_PSNR: 25.3085 - val_loss: 0.0075 - val_mean_PSNR: 22.3524\n",
      "Epoch 239/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:48:04.734329 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.181211). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0041 - mean_PSNR: 25.4339"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:48:05.354759 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.590638). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.3252\n",
      "Learning rate for epoch 239 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.0042 - mean_PSNR: 25.3179 - val_loss: 0.0075 - val_mean_PSNR: 22.3577\n",
      "Epoch 240/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:48:28.136103 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.173901). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0041 - mean_PSNR: 25.4418"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:48:28.761271 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.586982). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.3342\n",
      "Learning rate for epoch 240 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0042 - mean_PSNR: 25.3271 - val_loss: 0.0075 - val_mean_PSNR: 22.3500\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:48:46.275542 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.150048). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0041 - mean_PSNR: 25.4414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:48:46.895365 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.575058). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0042 - mean_PSNR: 25.3401\n",
      "Learning rate for epoch 241 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 907ms/step - loss: 0.0042 - mean_PSNR: 25.3325 - val_loss: 0.0075 - val_mean_PSNR: 22.3549\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:49:09.905425 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.166640). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0041 - mean_PSNR: 25.4449"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:49:10.528692 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.583353). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.3491\n",
      "Learning rate for epoch 242 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0042 - mean_PSNR: 25.3412 - val_loss: 0.0075 - val_mean_PSNR: 22.3550\n",
      "Epoch 243/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:49:28.128017 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.189369). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 55s - loss: 0.0040 - mean_PSNR: 25.4634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:49:28.748868 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.594717). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.3551\n",
      "Learning rate for epoch 243 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 915ms/step - loss: 0.0041 - mean_PSNR: 25.3472 - val_loss: 0.0075 - val_mean_PSNR: 22.3505\n",
      "Epoch 244/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:49:51.917752 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.165534). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0041 - mean_PSNR: 25.4506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:49:52.535707 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.583364). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.3666\n",
      "Learning rate for epoch 244 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0041 - mean_PSNR: 25.3589 - val_loss: 0.0075 - val_mean_PSNR: 22.3529\n",
      "Epoch 245/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:50:10.087692 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.171137). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0041 - mean_PSNR: 25.4761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:50:10.707680 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.585600). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.3665\n",
      "Learning rate for epoch 245 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 907ms/step - loss: 0.0041 - mean_PSNR: 25.3591 - val_loss: 0.0075 - val_mean_PSNR: 22.3576\n",
      "Epoch 246/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:50:33.691299 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.153725). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0041 - mean_PSNR: 25.4740"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:50:34.311150 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.576894). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.3816\n",
      "Learning rate for epoch 246 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0041 - mean_PSNR: 25.3739 - val_loss: 0.0075 - val_mean_PSNR: 22.3525\n",
      "Epoch 247/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:50:51.909796 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.215153). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0041 - mean_PSNR: 25.4939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:50:52.531699 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.607611). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.3867\n",
      "Learning rate for epoch 247 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 916ms/step - loss: 0.0041 - mean_PSNR: 25.3789 - val_loss: 0.0075 - val_mean_PSNR: 22.3562\n",
      "Epoch 248/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:51:15.743606 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.210178). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.4979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:51:16.365239 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.605123). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4001\n",
      "Learning rate for epoch 248 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0041 - mean_PSNR: 25.3918 - val_loss: 0.0075 - val_mean_PSNR: 22.3489\n",
      "Epoch 249/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:51:33.919883 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.190884). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.4945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:51:34.541469 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.595475). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4052\n",
      "Learning rate for epoch 249 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 907ms/step - loss: 0.0041 - mean_PSNR: 25.3975 - val_loss: 0.0075 - val_mean_PSNR: 22.3503\n",
      "Epoch 250/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:51:57.501364 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.161137). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:51:58.128095 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.580602). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4102\n",
      "Learning rate for epoch 250 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0041 - mean_PSNR: 25.4024 - val_loss: 0.0075 - val_mean_PSNR: 22.3471\n",
      "Epoch 251/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:52:15.684945 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.167923). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.5079"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:52:16.305533 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.584005). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4203\n",
      "Learning rate for epoch 251 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 904ms/step - loss: 0.0041 - mean_PSNR: 25.4122 - val_loss: 0.0076 - val_mean_PSNR: 22.3449\n",
      "Epoch 252/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:52:39.193054 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.161119). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0041 - mean_PSNR: 25.5277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:52:39.812070 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.581169). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4278\n",
      "Learning rate for epoch 252 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0041 - mean_PSNR: 25.4195 - val_loss: 0.0075 - val_mean_PSNR: 22.3451\n",
      "Epoch 253/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:52:57.352086 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.184479). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:52:57.978868 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.592285). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4303\n",
      "Learning rate for epoch 253 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 905ms/step - loss: 0.0041 - mean_PSNR: 25.4223 - val_loss: 0.0075 - val_mean_PSNR: 22.3438\n",
      "Epoch 254/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:53:20.853264 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.150772). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.5337"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:53:21.470824 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.575418). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4333\n",
      "Learning rate for epoch 254 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0041 - mean_PSNR: 25.4256 - val_loss: 0.0076 - val_mean_PSNR: 22.3369\n",
      "Epoch 255/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:53:38.994102 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.157248). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.5378"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:53:39.608243 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.578656). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4414\n",
      "Learning rate for epoch 255 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 905ms/step - loss: 0.0041 - mean_PSNR: 25.4333 - val_loss: 0.0076 - val_mean_PSNR: 22.3377\n",
      "Epoch 256/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:54:02.580501 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.202836). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5389"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:54:03.198353 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.601449). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4493\n",
      "Learning rate for epoch 256 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 700ms/step - loss: 0.0041 - mean_PSNR: 25.4412 - val_loss: 0.0075 - val_mean_PSNR: 22.3415\n",
      "Epoch 257/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:54:20.778790 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.175843). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5615"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:54:21.402245 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.587953). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4527\n",
      "Learning rate for epoch 257 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 906ms/step - loss: 0.0041 - mean_PSNR: 25.4446 - val_loss: 0.0075 - val_mean_PSNR: 22.3334\n",
      "Epoch 258/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:54:44.360201 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.172409). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:54:44.982769 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.586245). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4592\n",
      "Learning rate for epoch 258 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0041 - mean_PSNR: 25.4508 - val_loss: 0.0075 - val_mean_PSNR: 22.3334\n",
      "Epoch 259/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:55:02.537204 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.199907). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:55:03.157488 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.599987). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4693\n",
      "Learning rate for epoch 259 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 902ms/step - loss: 0.0041 - mean_PSNR: 25.4612 - val_loss: 0.0076 - val_mean_PSNR: 22.3352\n",
      "Epoch 260/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:55:26.007505 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.193011). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:55:26.630146 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.596942). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4712\n",
      "Learning rate for epoch 260 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 700ms/step - loss: 0.0041 - mean_PSNR: 25.4627 - val_loss: 0.0076 - val_mean_PSNR: 22.3364\n",
      "Epoch 261/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:55:44.210746 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.195029). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5603"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:55:44.833075 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.597547). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4781\n",
      "Learning rate for epoch 261 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 901ms/step - loss: 0.0041 - mean_PSNR: 25.4693 - val_loss: 0.0076 - val_mean_PSNR: 22.3339\n",
      "Epoch 262/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:56:07.646549 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.132376). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:56:08.267428 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.566220). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0041 - mean_PSNR: 25.4816\n",
      "Learning rate for epoch 262 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0041 - mean_PSNR: 25.4732 - val_loss: 0.0075 - val_mean_PSNR: 22.3359\n",
      "Epoch 263/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:56:25.823692 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.185650). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.5794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:56:26.444502 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.592857). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.4913\n",
      "Learning rate for epoch 263 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0040 - mean_PSNR: 25.4826 - val_loss: 0.0075 - val_mean_PSNR: 22.3272\n",
      "Epoch 264/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:56:49.187134 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.163327). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.5687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:56:49.807231 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.581707). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.4994\n",
      "Learning rate for epoch 264 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0040 - mean_PSNR: 25.4909 - val_loss: 0.0076 - val_mean_PSNR: 22.3215\n",
      "Epoch 265/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:57:07.360383 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.187235). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0040 - mean_PSNR: 25.6029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:57:07.979913 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.593650). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5020\n",
      "Learning rate for epoch 265 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 912ms/step - loss: 0.0040 - mean_PSNR: 25.4938 - val_loss: 0.0076 - val_mean_PSNR: 22.3351\n",
      "Epoch 266/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:57:31.070724 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.171544). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.6020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:57:31.697817 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.585803). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5059\n",
      "Learning rate for epoch 266 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0040 - mean_PSNR: 25.4977 - val_loss: 0.0076 - val_mean_PSNR: 22.3259\n",
      "Epoch 267/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:57:49.224311 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.173599). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.6100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:57:49.846248 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.586829). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5138\n",
      "Learning rate for epoch 267 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.0040 - mean_PSNR: 25.5055 - val_loss: 0.0076 - val_mean_PSNR: 22.3193\n",
      "Epoch 268/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:58:12.616318 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.149622). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.6047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:58:13.242624 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.575229). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5186\n",
      "Learning rate for epoch 268 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0040 - mean_PSNR: 25.5103 - val_loss: 0.0076 - val_mean_PSNR: 22.3201\n",
      "Epoch 269/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:58:30.779818 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.163037). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.6101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:58:31.404930 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.581549). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5266\n",
      "Learning rate for epoch 269 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 912ms/step - loss: 0.0040 - mean_PSNR: 25.5176 - val_loss: 0.0076 - val_mean_PSNR: 22.3229\n",
      "Epoch 270/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:58:54.519026 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.159010). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.6132"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:58:55.139921 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.579535). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5278\n",
      "Learning rate for epoch 270 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0040 - mean_PSNR: 25.5192 - val_loss: 0.0076 - val_mean_PSNR: 22.3259\n",
      "Epoch 271/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:59:12.680277 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.152605). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.6169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:59:13.303332 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.576334). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5370\n",
      "Learning rate for epoch 271 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 924ms/step - loss: 0.0040 - mean_PSNR: 25.5284 - val_loss: 0.0076 - val_mean_PSNR: 22.3237\n",
      "Epoch 272/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:59:36.716944 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.150340). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.6135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:59:37.335414 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.575202). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5406\n",
      "Learning rate for epoch 272 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0040 - mean_PSNR: 25.5319 - val_loss: 0.0076 - val_mean_PSNR: 22.3178\n",
      "Epoch 273/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:59:54.916674 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.175954). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.6333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 17:59:55.541334 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.588009). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5434\n",
      "Learning rate for epoch 273 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 912ms/step - loss: 0.0040 - mean_PSNR: 25.5353 - val_loss: 0.0076 - val_mean_PSNR: 22.3101\n",
      "Epoch 274/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:00:18.655774 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.189809). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.6273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:00:19.278198 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.594936). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5496\n",
      "Learning rate for epoch 274 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0040 - mean_PSNR: 25.5412 - val_loss: 0.0076 - val_mean_PSNR: 22.3057\n",
      "Epoch 275/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:00:36.826603 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.160588). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.6420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:00:37.445469 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.580326). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5533\n",
      "Learning rate for epoch 275 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.0040 - mean_PSNR: 25.5447 - val_loss: 0.0076 - val_mean_PSNR: 22.3177\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:01:00.235307 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.158009). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0040 - mean_PSNR: 25.6469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:01:00.857561 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.579438). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5599\n",
      "Learning rate for epoch 276 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0040 - mean_PSNR: 25.5508 - val_loss: 0.0076 - val_mean_PSNR: 22.3156\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:01:18.401226 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.154202). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.6476"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:01:19.019922 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.577133). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5668\n",
      "Learning rate for epoch 277 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 901ms/step - loss: 0.0040 - mean_PSNR: 25.5580 - val_loss: 0.0076 - val_mean_PSNR: 22.3147\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:01:41.871873 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.179659). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.6660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:01:42.491886 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.589862). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5647\n",
      "Learning rate for epoch 278 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0040 - mean_PSNR: 25.5562 - val_loss: 0.0076 - val_mean_PSNR: 22.3053\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:02:00.028264 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.161097). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.6585"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:02:00.648681 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.580581). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5779\n",
      "Learning rate for epoch 279 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 913ms/step - loss: 0.0040 - mean_PSNR: 25.5693 - val_loss: 0.0076 - val_mean_PSNR: 22.2980\n",
      "Epoch 280/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:02:23.847157 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.180452). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.6679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:02:24.465901 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.590258). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5779\n",
      "Learning rate for epoch 280 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0040 - mean_PSNR: 25.5699 - val_loss: 0.0076 - val_mean_PSNR: 22.3004\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:02:42.023311 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.191165). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.6586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:02:42.643475 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.595615). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5879\n",
      "Learning rate for epoch 281 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 901ms/step - loss: 0.0040 - mean_PSNR: 25.5787 - val_loss: 0.0076 - val_mean_PSNR: 22.3038\n",
      "Epoch 282/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:03:05.458063 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.180231). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.6716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:03:06.075599 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.590148). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5854\n",
      "Learning rate for epoch 282 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0040 - mean_PSNR: 25.5767 - val_loss: 0.0076 - val_mean_PSNR: 22.2890\n",
      "Epoch 283/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:03:23.626046 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.177311). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.6829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:03:24.251698 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.588688). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5938\n",
      "Learning rate for epoch 283 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 914ms/step - loss: 0.0040 - mean_PSNR: 25.5852 - val_loss: 0.0076 - val_mean_PSNR: 22.2864\n",
      "Epoch 284/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:03:47.366580 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.141814). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.6781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:03:47.981692 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.571331). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.5995\n",
      "Learning rate for epoch 284 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0040 - mean_PSNR: 25.5905 - val_loss: 0.0076 - val_mean_PSNR: 22.2830\n",
      "Epoch 285/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:04:05.502696 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.138544). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0039 - mean_PSNR: 25.6841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:04:06.118867 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.569304). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.6033\n",
      "Learning rate for epoch 285 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0040 - mean_PSNR: 25.5945 - val_loss: 0.0076 - val_mean_PSNR: 22.2774\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:04:28.909191 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.139551). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.6891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:04:29.521638 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.569809). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.6063\n",
      "Learning rate for epoch 286 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0040 - mean_PSNR: 25.5973 - val_loss: 0.0077 - val_mean_PSNR: 22.2842\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:04:47.063528 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.153920). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.6973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:04:47.685348 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.576993). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.6151\n",
      "Learning rate for epoch 287 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0040 - mean_PSNR: 25.6060 - val_loss: 0.0076 - val_mean_PSNR: 22.2758\n",
      "Epoch 288/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:05:10.452286 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.142920). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.6938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:05:11.075378 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.571493). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.6176\n",
      "Learning rate for epoch 288 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0040 - mean_PSNR: 25.6087 - val_loss: 0.0076 - val_mean_PSNR: 22.2725\n",
      "Epoch 289/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:05:28.658270 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.182339). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.6910"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:05:29.282596 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.591203). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0040 - mean_PSNR: 25.6174\n",
      "Learning rate for epoch 289 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.0040 - mean_PSNR: 25.6087 - val_loss: 0.0077 - val_mean_PSNR: 22.2669\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:05:52.038804 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.147896). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.6961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:05:52.654171 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.573980). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6266\n",
      "Learning rate for epoch 290 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0040 - mean_PSNR: 25.6178 - val_loss: 0.0077 - val_mean_PSNR: 22.2708\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:06:10.140938 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.134058). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0039 - mean_PSNR: 25.7054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:06:10.759678 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.567061). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6283\n",
      "Learning rate for epoch 291 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 916ms/step - loss: 0.0040 - mean_PSNR: 25.6196 - val_loss: 0.0077 - val_mean_PSNR: 22.2611\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:06:34.005517 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.167553). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:06:34.627672 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.584199). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6332\n",
      "Learning rate for epoch 292 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0039 - mean_PSNR: 25.6243 - val_loss: 0.0076 - val_mean_PSNR: 22.2621\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:06:52.161944 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.160333). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:06:52.781995 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.580198). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6340\n",
      "Learning rate for epoch 293 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0039 - mean_PSNR: 25.6255 - val_loss: 0.0077 - val_mean_PSNR: 22.2584\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:07:15.554888 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.169573). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:07:16.174410 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.584821). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6405\n",
      "Learning rate for epoch 294 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6319 - val_loss: 0.0077 - val_mean_PSNR: 22.2603\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:07:33.661943 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.151707). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7326"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:07:34.282415 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.575885). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6387\n",
      "Learning rate for epoch 295 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0039 - mean_PSNR: 25.6300 - val_loss: 0.0077 - val_mean_PSNR: 22.2514\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:07:57.066510 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.147650). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.7318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:07:57.691741 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.573858). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6430\n",
      "Learning rate for epoch 296 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 21s 793ms/step - loss: 0.0039 - mean_PSNR: 25.6338 - val_loss: 0.0077 - val_mean_PSNR: 22.2385\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:08:17.696219 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.177902). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.7456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:08:18.320684 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.588983). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6401\n",
      "Learning rate for epoch 297 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 901ms/step - loss: 0.0039 - mean_PSNR: 25.6308 - val_loss: 0.0077 - val_mean_PSNR: 22.2333\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:08:41.134283 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.166576). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.7377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:08:41.763051 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.583319). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6443\n",
      "Learning rate for epoch 298 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 21s 790ms/step - loss: 0.0039 - mean_PSNR: 25.6352 - val_loss: 0.0077 - val_mean_PSNR: 22.2368\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:09:01.686095 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.154403). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:09:02.311782 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.577234). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6496\n",
      "Learning rate for epoch 299 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 24s 910ms/step - loss: 0.0039 - mean_PSNR: 25.6407 - val_loss: 0.0077 - val_mean_PSNR: 22.2330\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:09:25.382975 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.179646). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0039 - mean_PSNR: 25.7341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:09:26.007666 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.590230). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6535\n",
      "Learning rate for epoch 300 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 699ms/step - loss: 0.0039 - mean_PSNR: 25.6447 - val_loss: 0.0077 - val_mean_PSNR: 22.2288\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:09:43.617793 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.195788). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 55s - loss: 0.0039 - mean_PSNR: 25.7428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:09:44.236363 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.597926). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6568\n",
      "Learning rate for epoch 301 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 902ms/step - loss: 0.0039 - mean_PSNR: 25.6481 - val_loss: 0.0077 - val_mean_PSNR: 22.2153\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:10:07.083582 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.196494). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 55s - loss: 0.0039 - mean_PSNR: 25.7383"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:10:07.704998 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.598280). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6604\n",
      "Learning rate for epoch 302 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 700ms/step - loss: 0.0039 - mean_PSNR: 25.6515 - val_loss: 0.0077 - val_mean_PSNR: 22.2230\n",
      "Epoch 303/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:10:25.198828 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.134680). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0039 - mean_PSNR: 25.7479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:10:25.820808 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.567373). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6589\n",
      "Learning rate for epoch 303 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 902ms/step - loss: 0.0039 - mean_PSNR: 25.6502 - val_loss: 0.0077 - val_mean_PSNR: 22.2214\n",
      "Epoch 304/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:10:48.684477 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.149816). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:10:49.301219 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.574941). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6694\n",
      "Learning rate for epoch 304 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6602 - val_loss: 0.0077 - val_mean_PSNR: 22.2179\n",
      "Epoch 305/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:11:06.823771 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.161778). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:11:07.446487 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.580920). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6775\n",
      "Learning rate for epoch 305 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0039 - mean_PSNR: 25.6680 - val_loss: 0.0077 - val_mean_PSNR: 22.2266\n",
      "Epoch 306/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:11:30.216296 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.150226). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:11:30.836413 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.575145). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6806\n",
      "Learning rate for epoch 306 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6715 - val_loss: 0.0077 - val_mean_PSNR: 22.2314\n",
      "Epoch 307/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:11:48.340121 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.155529). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:11:48.963720 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.577808). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6835\n",
      "Learning rate for epoch 307 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0039 - mean_PSNR: 25.6740 - val_loss: 0.0077 - val_mean_PSNR: 22.2297\n",
      "Epoch 308/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:12:11.735851 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.155334). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7680"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:12:12.353325 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.578088). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6927\n",
      "Learning rate for epoch 308 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6835 - val_loss: 0.0077 - val_mean_PSNR: 22.2026\n",
      "Epoch 309/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:12:29.844619 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.136523). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0038 - mean_PSNR: 25.7643"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:12:30.463011 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.568293). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6864\n",
      "Learning rate for epoch 309 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0039 - mean_PSNR: 25.6781 - val_loss: 0.0078 - val_mean_PSNR: 22.1992\n",
      "Epoch 310/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:12:53.226543 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.157901). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:12:53.841540 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.578990). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6814\n",
      "Learning rate for epoch 310 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6732 - val_loss: 0.0078 - val_mean_PSNR: 22.1932\n",
      "Epoch 311/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:13:11.375739 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.155610). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:13:11.993227 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.577837). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6894\n",
      "Learning rate for epoch 311 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.0039 - mean_PSNR: 25.6809 - val_loss: 0.0078 - val_mean_PSNR: 22.1807\n",
      "Epoch 312/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:13:34.759769 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.153732). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7620"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:13:35.379573 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.576898). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6834\n",
      "Learning rate for epoch 312 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6750 - val_loss: 0.0077 - val_mean_PSNR: 22.1950\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:13:52.906503 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.149806). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:13:53.530056 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.574934). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6914\n",
      "Learning rate for epoch 313 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0039 - mean_PSNR: 25.6826 - val_loss: 0.0078 - val_mean_PSNR: 22.1822\n",
      "Epoch 314/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:14:16.275093 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.158771). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7944"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:14:16.897957 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.579418). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6987\n",
      "Learning rate for epoch 314 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6899 - val_loss: 0.0078 - val_mean_PSNR: 22.1649\n",
      "Epoch 315/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:14:34.391746 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.131957). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0039 - mean_PSNR: 25.7918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:14:35.009939 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.566009). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6832\n",
      "Learning rate for epoch 315 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 897ms/step - loss: 0.0039 - mean_PSNR: 25.6747 - val_loss: 0.0078 - val_mean_PSNR: 22.1541\n",
      "Epoch 316/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:14:57.767942 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.154275). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7765"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:14:58.388029 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.577538). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6882\n",
      "Learning rate for epoch 316 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6795 - val_loss: 0.0079 - val_mean_PSNR: 22.1323\n",
      "Epoch 317/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:15:15.961013 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.169066). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0038 - mean_PSNR: 25.7823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:15:16.582748 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.584565). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6905\n",
      "Learning rate for epoch 317 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 901ms/step - loss: 0.0039 - mean_PSNR: 25.6813 - val_loss: 0.0079 - val_mean_PSNR: 22.1426\n",
      "Epoch 318/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:15:39.363201 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.175717). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:15:39.978118 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.587890). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6797\n",
      "Learning rate for epoch 318 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 695ms/step - loss: 0.0039 - mean_PSNR: 25.6715 - val_loss: 0.0079 - val_mean_PSNR: 22.1448\n",
      "Epoch 319/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:15:57.487414 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.190188). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0038 - mean_PSNR: 25.7847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:15:58.107539 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.595126). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6881\n",
      "Learning rate for epoch 319 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0039 - mean_PSNR: 25.6781 - val_loss: 0.0079 - val_mean_PSNR: 22.1123\n",
      "Epoch 320/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:16:20.850241 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.164523). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7675"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:16:21.467130 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.582299). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6911\n",
      "Learning rate for epoch 320 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6818 - val_loss: 0.0079 - val_mean_PSNR: 22.0890\n",
      "Epoch 321/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:16:38.991583 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.162193). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7680"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:16:39.606670 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.581128). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6766\n",
      "Learning rate for epoch 321 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0039 - mean_PSNR: 25.6686 - val_loss: 0.0079 - val_mean_PSNR: 22.1246\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:17:02.373062 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.177557). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:17:02.990247 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.588811). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6798\n",
      "Learning rate for epoch 322 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6701 - val_loss: 0.0079 - val_mean_PSNR: 22.1325\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:17:20.519259 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.170656). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:17:21.138149 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.585360). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6783\n",
      "Learning rate for epoch 323 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.0039 - mean_PSNR: 25.6686 - val_loss: 0.0079 - val_mean_PSNR: 22.1139\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:17:43.937901 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.170028). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:17:44.558259 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.585447). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6801\n",
      "Learning rate for epoch 324 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0039 - mean_PSNR: 25.6712 - val_loss: 0.0079 - val_mean_PSNR: 22.1384\n",
      "Epoch 325/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:18:02.099394 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.178936). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:18:02.716976 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.589502). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6808\n",
      "Learning rate for epoch 325 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0039 - mean_PSNR: 25.6723 - val_loss: 0.0079 - val_mean_PSNR: 22.1415\n",
      "Epoch 326/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:18:25.440792 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.146422). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0039 - mean_PSNR: 25.7671"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:18:26.061260 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.573244). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6917\n",
      "Learning rate for epoch 326 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.6832 - val_loss: 0.0078 - val_mean_PSNR: 22.1533\n",
      "Epoch 327/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:18:43.596909 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.153940). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7790"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:18:44.216922 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.577002). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6961\n",
      "Learning rate for epoch 327 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.0039 - mean_PSNR: 25.6878 - val_loss: 0.0078 - val_mean_PSNR: 22.1811\n",
      "Epoch 328/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:19:07.018646 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.161420). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:19:07.639492 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.580742). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.6960\n",
      "Learning rate for epoch 328 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0039 - mean_PSNR: 25.6882 - val_loss: 0.0078 - val_mean_PSNR: 22.1841\n",
      "Epoch 329/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:19:25.183670 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.163040). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:19:25.806296 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.581552). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7105\n",
      "Learning rate for epoch 329 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0039 - mean_PSNR: 25.7023 - val_loss: 0.0078 - val_mean_PSNR: 22.1917\n",
      "Epoch 330/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:19:48.569742 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.155552). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:19:49.193511 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.577808). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7143\n",
      "Learning rate for epoch 330 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.7060 - val_loss: 0.0078 - val_mean_PSNR: 22.2029\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:20:06.686077 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.134226). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0038 - mean_PSNR: 25.7880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:20:07.303261 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.567146). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7235\n",
      "Learning rate for epoch 331 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 901ms/step - loss: 0.0039 - mean_PSNR: 25.7136 - val_loss: 0.0078 - val_mean_PSNR: 22.1696\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:20:30.164579 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.157996). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:20:30.783216 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.579438). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7263\n",
      "Learning rate for epoch 332 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.7166 - val_loss: 0.0078 - val_mean_PSNR: 22.1601\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:20:48.280132 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.146023). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:20:48.896345 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.573044). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7251\n",
      "Learning rate for epoch 333 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0039 - mean_PSNR: 25.7152 - val_loss: 0.0078 - val_mean_PSNR: 22.1667\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:21:11.647413 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.144983). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7566"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:21:12.266754 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.572522). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7161\n",
      "Learning rate for epoch 334 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0039 - mean_PSNR: 25.7084 - val_loss: 0.0078 - val_mean_PSNR: 22.1930\n",
      "Epoch 335/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:21:29.735147 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.127244). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0038 - mean_PSNR: 25.7847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:21:30.356826 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.563653). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7062\n",
      "Learning rate for epoch 335 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 897ms/step - loss: 0.0039 - mean_PSNR: 25.6977 - val_loss: 0.0078 - val_mean_PSNR: 22.2194\n",
      "Epoch 336/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:21:53.118559 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.153333). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:21:53.735517 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.576698). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7149\n",
      "Learning rate for epoch 336 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0039 - mean_PSNR: 25.7056 - val_loss: 0.0078 - val_mean_PSNR: 22.1806\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:22:11.197645 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.151332). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:22:11.818361 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.575697). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7314\n",
      "Learning rate for epoch 337 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 897ms/step - loss: 0.0039 - mean_PSNR: 25.7218 - val_loss: 0.0078 - val_mean_PSNR: 22.1501\n",
      "Epoch 338/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:22:34.558315 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.160780). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:22:35.181656 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.580423). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7511\n",
      "Learning rate for epoch 338 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0039 - mean_PSNR: 25.7416 - val_loss: 0.0078 - val_mean_PSNR: 22.1821\n",
      "Epoch 339/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:22:52.675278 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.166897). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.7710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:22:53.297014 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.583480). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7611\n",
      "Learning rate for epoch 339 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0039 - mean_PSNR: 25.7509 - val_loss: 0.0079 - val_mean_PSNR: 22.1210\n",
      "Epoch 340/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:23:16.061706 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.142327). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.7839"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:23:16.681505 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.571577). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7688\n",
      "Learning rate for epoch 340 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.7589 - val_loss: 0.0079 - val_mean_PSNR: 22.0983\n",
      "Epoch 341/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:23:34.159016 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.125548). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0038 - mean_PSNR: 25.7683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:23:34.774384 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.562805). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7708\n",
      "Learning rate for epoch 341 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 896ms/step - loss: 0.0039 - mean_PSNR: 25.7620 - val_loss: 0.0079 - val_mean_PSNR: 22.1297\n",
      "Epoch 342/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:23:57.519904 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.148518). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0039 - mean_PSNR: 25.8110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:23:58.143149 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.574290). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7652\n",
      "Learning rate for epoch 342 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0039 - mean_PSNR: 25.7561 - val_loss: 0.0079 - val_mean_PSNR: 22.1190\n",
      "Epoch 343/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:24:15.662009 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.161644). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:24:16.282822 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.580854). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7806\n",
      "Learning rate for epoch 343 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0038 - mean_PSNR: 25.7713 - val_loss: 0.0079 - val_mean_PSNR: 22.1253\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:24:39.032623 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.138121). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:24:39.653275 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.569092). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7819\n",
      "Learning rate for epoch 344 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0038 - mean_PSNR: 25.7723 - val_loss: 0.0079 - val_mean_PSNR: 22.1186\n",
      "Epoch 345/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:24:57.157418 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.135563). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:24:57.780920 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.567812). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7927\n",
      "Learning rate for epoch 345 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0038 - mean_PSNR: 25.7836 - val_loss: 0.0079 - val_mean_PSNR: 22.1388\n",
      "Epoch 346/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:25:20.537639 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.154190). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8195"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:25:21.156785 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.577127). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7810\n",
      "Learning rate for epoch 346 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0038 - mean_PSNR: 25.7719 - val_loss: 0.0079 - val_mean_PSNR: 22.1252\n",
      "Epoch 347/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:25:38.656466 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.138512). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:25:39.271084 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.569287). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7890\n",
      "Learning rate for epoch 347 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0038 - mean_PSNR: 25.7807 - val_loss: 0.0079 - val_mean_PSNR: 22.1304\n",
      "Epoch 348/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:26:01.996744 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.135770). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0038 - mean_PSNR: 25.8408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:26:02.618196 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.568331). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7880\n",
      "Learning rate for epoch 348 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0038 - mean_PSNR: 25.7801 - val_loss: 0.0079 - val_mean_PSNR: 22.1165\n",
      "Epoch 349/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:26:20.094164 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.133627). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0038 - mean_PSNR: 25.8530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:26:20.712862 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.566845). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7863\n",
      "Learning rate for epoch 349 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0038 - mean_PSNR: 25.7785 - val_loss: 0.0079 - val_mean_PSNR: 22.1258\n",
      "Epoch 350/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:26:43.433817 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.131047). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0038 - mean_PSNR: 25.8679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:26:44.053021 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.565554). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7828\n",
      "Learning rate for epoch 350 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 695ms/step - loss: 0.0038 - mean_PSNR: 25.7754 - val_loss: 0.0079 - val_mean_PSNR: 22.1446\n",
      "Epoch 351/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:27:01.548742 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.159132). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:27:02.173010 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.579608). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7826\n",
      "Learning rate for epoch 351 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 898ms/step - loss: 0.0038 - mean_PSNR: 25.7752 - val_loss: 0.0080 - val_mean_PSNR: 22.1334\n",
      "Epoch 352/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:27:24.918079 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.153625). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:27:25.536785 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.576845). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7918\n",
      "Learning rate for epoch 352 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0038 - mean_PSNR: 25.7844 - val_loss: 0.0079 - val_mean_PSNR: 22.1254\n",
      "Epoch 353/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:27:43.016424 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.154305). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:27:43.631911 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.577185). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7884\n",
      "Learning rate for epoch 353 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 895ms/step - loss: 0.0038 - mean_PSNR: 25.7801 - val_loss: 0.0080 - val_mean_PSNR: 22.1000\n",
      "Epoch 354/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:28:06.289866 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.137867). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:28:06.908473 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.568965). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7906\n",
      "Learning rate for epoch 354 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0038 - mean_PSNR: 25.7824 - val_loss: 0.0080 - val_mean_PSNR: 22.1106\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:28:24.450442 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.184302). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 54s - loss: 0.0038 - mean_PSNR: 25.8655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:28:25.078055 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.592183). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7917\n",
      "Learning rate for epoch 355 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 900ms/step - loss: 0.0038 - mean_PSNR: 25.7834 - val_loss: 0.0080 - val_mean_PSNR: 22.0900\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:28:47.850023 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.135350). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:28:48.472206 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.568103). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7909\n",
      "Learning rate for epoch 356 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 698ms/step - loss: 0.0039 - mean_PSNR: 25.7837 - val_loss: 0.0081 - val_mean_PSNR: 22.0827\n",
      "Epoch 357/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:29:05.975071 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.150807). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:29:06.597558 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.575444). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7966\n",
      "Learning rate for epoch 357 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 897ms/step - loss: 0.0038 - mean_PSNR: 25.7885 - val_loss: 0.0081 - val_mean_PSNR: 22.0678\n",
      "Epoch 358/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:29:29.304204 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.149703). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:29:29.926556 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.574883). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7907\n",
      "Learning rate for epoch 358 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 695ms/step - loss: 0.0039 - mean_PSNR: 25.7824 - val_loss: 0.0081 - val_mean_PSNR: 22.0675\n",
      "Epoch 359/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:29:47.388171 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.156071). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:29:48.005449 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.578068). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7962\n",
      "Learning rate for epoch 359 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 894ms/step - loss: 0.0039 - mean_PSNR: 25.7877 - val_loss: 0.0081 - val_mean_PSNR: 22.0612\n",
      "Epoch 360/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:30:10.677658 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.158160). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8820"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:30:11.296779 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.579113). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0039 - mean_PSNR: 25.7956\n",
      "Learning rate for epoch 360 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 696ms/step - loss: 0.0039 - mean_PSNR: 25.7870 - val_loss: 0.0081 - val_mean_PSNR: 22.0526\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:30:28.735124 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.126756). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0038 - mean_PSNR: 25.8876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:30:29.349538 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.563419). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.7991\n",
      "Learning rate for epoch 361 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 897ms/step - loss: 0.0039 - mean_PSNR: 25.7907 - val_loss: 0.0081 - val_mean_PSNR: 22.0544\n",
      "Epoch 362/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:30:52.083360 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.140894). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 52s - loss: 0.0038 - mean_PSNR: 25.8912"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:30:52.704302 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.570478). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.8176\n",
      "Learning rate for epoch 362 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 695ms/step - loss: 0.0038 - mean_PSNR: 25.8077 - val_loss: 0.0080 - val_mean_PSNR: 22.0893\n",
      "Epoch 363/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:31:10.224935 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.153276). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.8790"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:31:10.841853 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.576670). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.8165\n",
      "Learning rate for epoch 363 is 6.374999884428689e-06\n",
      "26/26 [==============================] - 23s 899ms/step - loss: 0.0038 - mean_PSNR: 25.8078 - val_loss: 0.0080 - val_mean_PSNR: 22.0658\n",
      "Epoch 364/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:31:33.620496 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.162533). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.9015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:31:34.243781 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.581679). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.8227\n",
      "Learning rate for epoch 364 is 2.5499999537714757e-05\n",
      "26/26 [==============================] - 18s 697ms/step - loss: 0.0038 - mean_PSNR: 25.8140 - val_loss: 0.0080 - val_mean_PSNR: 22.0812\n",
      "Epoch 365/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:31:51.738807 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (1.147928). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/26 [>.............................] - ETA: 53s - loss: 0.0038 - mean_PSNR: 25.9275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0531 18:31:52.358761 140181555341056 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.573996). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/26 [===========================>..] - ETA: 0s - loss: 0.0038 - mean_PSNR: 25.8182"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bc9049b0dc2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     use_multiprocessing=True) # see if speeds things up\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m       \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_log_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mweight_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m           \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2978\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_in_graph_mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;31m# This is a variable which was created in an eager context, but is being\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    910\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m       \u001b[0mcopied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mcopied\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_data\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_copy\u001b[0;34m(self, ctx, device_name)\u001b[0m\n\u001b[1;32m    892\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;34m\"\"\"Copies tensor to dest device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m     \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m     \u001b[0;31m# Record the copy on tape and define backprop copy as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_copy_nograd\u001b[0;34m(self, ctx, device_name)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m       \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=dev_dataset,\n",
    "    verbose=1, # set to 0 to suppress chatty output and use Tensorboard instead\n",
    "    epochs=1000,\n",
    "    callbacks=callbacks,\n",
    "    use_multiprocessing=True) # see if speeds things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Uncomment to save model\n",
    "# saved_model_path = 'automap_our_dataset_original_paper_model_with_up_down_sampling' (had out 256 channels... bad)\n",
    "\n",
    "saved_model_path = 'automap_our_dataset_original_paper_model_with_up_down_sampling_single_GPU_small_FC_v6'\n",
    "\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"loss\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_loss\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_history.history[\"mean_PSNR\"], label=\"Train\")\n",
    "plt.plot(training_history.history[\"val_mean_PSNR\"], label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\" ( PSNR ) \")\n",
    "plt.legend(loc=\"center right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict on a test batch\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    x, y = x.numpy(), y.numpy()\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    # Inspect output\n",
    "\n",
    "    for i in range(len(x)):\n",
    "\n",
    "        fft_mag = x[i, ..., 0]\n",
    "        fft_ang = x[i, ..., 1]\n",
    "        c = None #int(cls[i])\n",
    "        reconstruction = y_pred[i, ..., 0]\n",
    "        reconstruction[reconstruction < 0] = 0\n",
    "        reconstruction[reconstruction > 1] = 1\n",
    "        image = y[i, ..., 0]\n",
    "\n",
    "        print('Class: {}'.format(c))\n",
    "\n",
    "        MSE = utils.signal_processing.mean_square_error(reconstruction, image)\n",
    "        PSNR = utils.signal_processing.PSNR(reconstruction, image, max_value=1.0)\n",
    "\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.title('Reconstruction (MSE: {:0.5f}, PSNR: {:0.5f})'.format(MSE, PSNR))\n",
    "        utils.plot.imshowgray(reconstruction)\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.title('FFT (Magnitude)')\n",
    "        utils.plot.imshowfft(fft_mag)\n",
    "\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.title('Expected reconstruction')\n",
    "        utils.plot.imshowgray(image)\n",
    "\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.title('FFT (Phase)')\n",
    "        utils.plot.imshowgray(fft_ang)\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In theory, in TF 2.0 we should be able to see Tensorboard in this notebook with magics:\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir logs\n",
    "\n",
    "# Clear logs if needed\n",
    "# !rm -rf logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/1l4z7u062nvlhrz/MRI_Kspace.dat\n",
    "# See https://github.com/kmjohnson3/ML4MI_BootCamp/blob/fe9d96cd9f68db073a44f9dc9a015533a008d0a7/ImageReconstruction/CoLab_AutoMap_Recon.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll -h MRI_Kspace.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore these old models (here for ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "#     N = 256\n",
    "#     small_N = N // 4 # after downsampling by 2 twice\n",
    "    \n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-6)(X)\n",
    "#     conv_downsample1 = tf.keras.layers.Conv2D(16, (4, 4), strides=(2, 2), activation='tanh', padding='same')(noisy_X)\n",
    "# #     conv_downsample2 = tf.keras.layers.Conv2D(4, (4, 4), strides=(1, 1), activation='tanh', padding='same')(conv_downsample1)\n",
    "#     conv_downsample3 = tf.keras.layers.Conv2D(2, (4, 4), strides=(2, 2), activation='tanh', padding='same')(conv_downsample1)\n",
    "#     X1 = tf.keras.layers.Flatten()(conv_downsample3)\n",
    "    \n",
    "#     # Workaround for: ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.\n",
    "#     X1 = tf.keras.layers.Reshape(target_shape=((small_N ** 2) * 2,))(X1)\n",
    "    \n",
    "#     fc1 = tf.keras.layers.Dense((small_N ** 2) * 1, activation = 'tanh')(X1)\n",
    "#     fc1_DO = tf.keras.layers.Dropout(0.1)(fc1)\n",
    "    \n",
    "#     fc2 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc1_DO)\n",
    "#     fc2_DO = tf.keras.layers.Dropout(0.1)(fc2)\n",
    "\n",
    "#     fc3 = tf.keras.layers.Dense(small_N ** 2, activation = 'tanh')(fc2_DO)\n",
    "#     X2 = tf.keras.layers.Reshape((small_N, small_N, 1))(fc3)\n",
    "#     conv1_1 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(1e-4))(X2)\n",
    "#     conv1_2 = tf.keras.layers.Conv2D(small_N, 5, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l1(1e-4))(conv1_1)\n",
    "#     conv1_3a = tf.keras.layers.Conv2DTranspose(small_N, 9, activation='relu', padding='same')(conv1_2)\n",
    "#     conv1_3b = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3a)\n",
    "#     conv1_3c = tf.keras.layers.Conv2DTranspose(small_N, 9, strides=2, activation='relu', padding='same')(conv1_3b)\n",
    "    \n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, 1, activation = 'linear', padding='same')(conv1_3c)\n",
    "    \n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "    \n",
    "#     # this one's solid, but I believe we'll need a few hours to train it.\n",
    "    \n",
    "#     N = 256\n",
    "#     F = N\n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "#     # Half-assed data augmentation\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "#     # These layers all halve the spatial dimension (but also each output 256 channels)\n",
    "#     conv1 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "#     pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "#     conv2 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "#     pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "#     conv3 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "#     pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "#     conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "#     pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "#     conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4)\n",
    "#     pool5 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv5) # shape: (8, 8, F)\n",
    "\n",
    "#     conv6 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool5)\n",
    "#     pool6 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv6) # shape: (4, 4, F)\n",
    "\n",
    "#     # A \"FC-like\" layer for fun before we do upsampling\n",
    "#     conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(pool6) # spatial dim: 4\n",
    "\n",
    "#     # These transposed convolutions upsample spatial dimension by 2\n",
    "#     t_conv1 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(conv7) # spatial dim: 8\n",
    "#     t_conv2 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv1) # spatial dim: 16\n",
    "#     t_conv3 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv2) # spatial dim: 32\n",
    "#     t_conv4 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv3) # spatial dim: 64\n",
    "#     t_conv5 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv4) # spatial dim: 128\n",
    "    \n",
    "#     Y_pred = tf.keras.layers.Conv2DTranspose(1, 4, strides=2, activation='linear', padding='same')(t_conv5) # spatial dim: 256\n",
    "\n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "#     return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no transposed conv, just upsample (first try, guessing too much data lost in middle)\n",
    "\n",
    "# def load_uncompiled_automap_model():\n",
    "\n",
    "#     N = 256\n",
    "#     F = N\n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "#     # Half-assed data augmentation\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "#     # Downsampling\n",
    "\n",
    "#     conv1 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "#     pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "#     conv2 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "#     pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "#     conv3 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "#     pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "#     conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "#     pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "#     conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4)\n",
    "#     pool5 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv5) # shape: (8, 8, F)\n",
    "\n",
    "#     conv6 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool5)\n",
    "#     pool6 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv6) # shape: (4, 4, F)\n",
    "\n",
    "#     # Some pointwise convoluations before finally upsampling\n",
    "\n",
    "#     conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(pool6) # shape: (4, 4, F)\n",
    "#     conv8 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv7) # shape: (4, 4, F)\n",
    "#     conv9 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv8) # shape: (4, 4, F)\n",
    "\n",
    "#     # Upsampling\n",
    "\n",
    "#     conv10 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(conv9)\n",
    "#     pool10 = tf.keras.layers.UpSampling2D(2)(conv10) # shape: (8, 8, F)\n",
    "\n",
    "#     conv11 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool10)\n",
    "#     pool11 = tf.keras.layers.UpSampling2D(2)(conv11) # shape: (16, 16, F)\n",
    "\n",
    "#     conv12 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool11)\n",
    "#     pool12 = tf.keras.layers.UpSampling2D(2)(conv12) # shape: (32, 32, F)\n",
    "\n",
    "#     conv13 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool12)\n",
    "#     pool13 = tf.keras.layers.UpSampling2D(2)(conv13) # shape: (64, 64, F)\n",
    "\n",
    "#     conv14 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool13)\n",
    "#     pool14 = tf.keras.layers.UpSampling2D(2)(conv14) # shape: (128, 128, F)\n",
    "\n",
    "#     conv15 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool14)\n",
    "#     pool15 = tf.keras.layers.UpSampling2D(2)(conv15) # shape: (256, 256, F)\n",
    "\n",
    "#     # One more to smooth things out\n",
    "\n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, (3, 3), strides=(1, 1), activation='linear', padding='same')(pool15)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_uncompiled_automap_model():\n",
    "\n",
    "#     N = 256\n",
    "#     F = N\n",
    "#     X = tf.keras.layers.Input(shape=(N, N, 2))\n",
    "\n",
    "#     # Half-assed data augmentation\n",
    "#     noisy_X = tf.keras.layers.GaussianNoise(stddev=1e-7)(X) # shape: (256, 256, 256)\n",
    "\n",
    "#     # Downsampling\n",
    "\n",
    "#     conv1 = tf.keras.layers.Conv2D(F, (9, 9), strides=(1, 1), activation='relu', padding='same')(noisy_X)\n",
    "#     pool1 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv1) # shape: (128, 128, F)\n",
    "\n",
    "#     conv2 = tf.keras.layers.Conv2D(F, (7, 7), strides=(1, 1), activation='relu', padding='same')(pool1)\n",
    "#     pool2 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv2) # shape: (64, 64, F)\n",
    "\n",
    "#     conv3 = tf.keras.layers.Conv2D(F, (5, 5), strides=(1, 1), activation='relu', padding='same')(pool2)\n",
    "#     pool3 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv3) # shape: (32, 32, F)\n",
    "\n",
    "#     conv4 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool3)\n",
    "#     pool4 = tf.keras.layers.AveragePooling2D(pool_size=2)(conv4) # shape: (16, 16, F)\n",
    "\n",
    "#     # Some pointwise convolutions before finally upsampling\n",
    "\n",
    "#     conv5 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool4) # shape: (16, 16, F)\n",
    "#     conv6 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv5) # shape: (16, 16, F)\n",
    "#     conv7 = tf.keras.layers.Conv2D(F, (1, 1), strides=(1, 1), activation='relu', padding='same')(conv6) # shape: (16, 16, F)\n",
    "\n",
    "#     # Upsampling\n",
    "\n",
    "#     t_conv8 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(conv7)\n",
    "#     t_conv9 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv8)\n",
    "#     t_conv10 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv9)\n",
    "#     t_conv11 = tf.keras.layers.Conv2DTranspose(F, 4, strides=2, activation='relu', padding='same')(t_conv10)\n",
    "    \n",
    "# #     pool8 = tf.keras.layers.UpSampling2D(2)(conv7) # shape: (32, 32, F)\n",
    "# #     conv8 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool8)\n",
    "\n",
    "# #     pool9 = tf.keras.layers.UpSampling2D(2)(conv8) # shape: (64, 64, F)\n",
    "# #     conv9 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool9)\n",
    "\n",
    "# #     pool10 = tf.keras.layers.UpSampling2D(2)(conv9) # shape: (128, 128, F)\n",
    "# #     conv10 = tf.keras.layers.Conv2D(F, (3, 3), strides=(1, 1), activation='relu', padding='same')(pool10)\n",
    "\n",
    "# #     pool11 = tf.keras.layers.UpSampling2D(2)(conv10) # shape: (256, 256, F)\n",
    "# #     conv11 = tf.keras.layers.Conv2D(F, (5, 5), strides=(1, 1), activation='relu', padding='same')(pool11)\n",
    "\n",
    "#     # One more to smooth things out\n",
    "\n",
    "#     Y_pred = tf.keras.layers.Conv2D(1, (2, 2), strides=(1, 1), activation='linear', padding='same')(t_conv11)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=X, outputs=Y_pred)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file1000000.h5\tfile1000350.h5\tfile1000925.h5\tfile1001365.h5\tfile1001938.h5\r\n",
      "file1000007.h5\tfile1000356.h5\tfile1000926.h5\tfile1001381.h5\tfile1001955.h5\r\n",
      "file1000017.h5\tfile1000389.h5\tfile1000932.h5\tfile1001429.h5\tfile1001959.h5\r\n",
      "file1000026.h5\tfile1000432.h5\tfile1000942.h5\tfile1001440.h5\tfile1001968.h5\r\n",
      "file1000031.h5\tfile1000464.h5\tfile1000972.h5\tfile1001444.h5\tfile1001977.h5\r\n",
      "file1000033.h5\tfile1000476.h5\tfile1000976.h5\tfile1001450.h5\tfile1001983.h5\r\n",
      "file1000041.h5\tfile1000477.h5\tfile1000990.h5\tfile1001458.h5\tfile1001984.h5\r\n",
      "file1000052.h5\tfile1000480.h5\tfile1001031.h5\tfile1001480.h5\tfile1001995.h5\r\n",
      "file1000071.h5\tfile1000496.h5\tfile1001057.h5\tfile1001497.h5\tfile1001997.h5\r\n",
      "file1000073.h5\tfile1000528.h5\tfile1001059.h5\tfile1001499.h5\tfile1002002.h5\r\n",
      "file1000107.h5\tfile1000537.h5\tfile1001064.h5\tfile1001506.h5\tfile1002007.h5\r\n",
      "file1000108.h5\tfile1000538.h5\tfile1001077.h5\tfile1001533.h5\tfile1002021.h5\r\n",
      "file1000114.h5\tfile1000552.h5\tfile1001090.h5\tfile1001557.h5\tfile1002035.h5\r\n",
      "file1000126.h5\tfile1000555.h5\tfile1001096.h5\tfile1001566.h5\tfile1002067.h5\r\n",
      "file1000153.h5\tfile1000591.h5\tfile1001104.h5\tfile1001585.h5\tfile1002145.h5\r\n",
      "file1000178.h5\tfile1000593.h5\tfile1001119.h5\tfile1001598.h5\tfile1002155.h5\r\n",
      "file1000182.h5\tfile1000625.h5\tfile1001122.h5\tfile1001643.h5\tfile1002159.h5\r\n",
      "file1000190.h5\tfile1000628.h5\tfile1001126.h5\tfile1001650.h5\tfile1002187.h5\r\n",
      "file1000196.h5\tfile1000631.h5\tfile1001140.h5\tfile1001651.h5\tfile1002214.h5\r\n",
      "file1000201.h5\tfile1000635.h5\tfile1001143.h5\tfile1001655.h5\tfile1002252.h5\r\n",
      "file1000206.h5\tfile1000647.h5\tfile1001144.h5\tfile1001668.h5\tfile1002257.h5\r\n",
      "file1000229.h5\tfile1000660.h5\tfile1001148.h5\tfile1001687.h5\tfile1002274.h5\r\n",
      "file1000243.h5\tfile1000697.h5\tfile1001159.h5\tfile1001689.h5\tfile1002280.h5\r\n",
      "file1000247.h5\tfile1000702.h5\tfile1001163.h5\tfile1001703.h5\tfile1002340.h5\r\n",
      "file1000254.h5\tfile1000735.h5\tfile1001168.h5\tfile1001715.h5\tfile1002351.h5\r\n",
      "file1000263.h5\tfile1000748.h5\tfile1001170.h5\tfile1001726.h5\tfile1002377.h5\r\n",
      "file1000264.h5\tfile1000758.h5\tfile1001184.h5\tfile1001759.h5\tfile1002380.h5\r\n",
      "file1000267.h5\tfile1000759.h5\tfile1001188.h5\tfile1001763.h5\tfile1002382.h5\r\n",
      "file1000273.h5\tfile1000769.h5\tfile1001191.h5\tfile1001793.h5\tfile1002389.h5\r\n",
      "file1000277.h5\tfile1000810.h5\tfile1001202.h5\tfile1001798.h5\tfile1002404.h5\r\n",
      "file1000280.h5\tfile1000817.h5\tfile1001219.h5\tfile1001818.h5\tfile1002412.h5\r\n",
      "file1000283.h5\tfile1000818.h5\tfile1001221.h5\tfile1001825.h5\tfile1002417.h5\r\n",
      "file1000291.h5\tfile1000831.h5\tfile1001262.h5\tfile1001834.h5\tfile1002436.h5\r\n",
      "file1000292.h5\tfile1000842.h5\tfile1001275.h5\tfile1001843.h5\tfile1002451.h5\r\n",
      "file1000308.h5\tfile1000858.h5\tfile1001289.h5\tfile1001850.h5\tfile1002515.h5\r\n",
      "file1000314.h5\tfile1000871.h5\tfile1001298.h5\tfile1001851.h5\tfile1002526.h5\r\n",
      "file1000323.h5\tfile1000885.h5\tfile1001331.h5\tfile1001862.h5\tfile1002538.h5\r\n",
      "file1000325.h5\tfile1000891.h5\tfile1001338.h5\tfile1001893.h5\tfile1002546.h5\r\n",
      "file1000328.h5\tfile1000899.h5\tfile1001339.h5\tfile1001916.h5\tfile1002570.h5\r\n",
      "file1000344.h5\tfile1000903.h5\tfile1001344.h5\tfile1001930.h5\r\n"
     ]
    }
   ],
   "source": [
    "# fastmri\n",
    "\n",
    "!ls ../../data/fastmri/singlecoil_val/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
